{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Making Sense of Data with Pandas\n",
    "\n",
    "Pandas stands for 'Python Data Analysis Library' and is a package designed to provide data scientists working in Python with a set of powerful tools to load, transform, and process large-ish data sets. As a result, it has become something of a *de facto* standard and many of the tutorials that you find online will probably make use of pandas at some point. It is provided by default with Anaconda Python.\n",
    "\n",
    "You will probably want to bookmark [the documentation](http://pandas.pydata.org/pandas-docs/stable/) since you will undoubtedly need to refer to it fairly regularly. _Note_: this link is to the most recent, stable release. If you are using an older version of pandas then you'll need to track it down from the [home page](http://pandas.pydata.org).\n",
    "\n",
    "You can always check what version you have installed like this:\n",
    "```python\n",
    "import pandas as pd\n",
    "print pd.__version__\n",
    "```\n",
    "This won't work with _all_ packages, but it will work with a lot of them. Remember that variables and methods starting and ending with '`__`' are **private**. So you shouldn't try to change this or manipulate it unless you really, really know what you are doing. Actually, just don't ever do it unless you're contributing to the package's development.\n",
    "\n",
    "Anyway, the main elements of pandas with which you interact directly are: 1) the DataFrame; 2) the Series. Let's take a look at one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "help(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On second thought, let's never do that again. Well, at least not _that_ way! You'll have noticed that the help documentation for the DataFrame is not just a bit longer than anything we've seen before, it's massively longer. There's probably quite a lot of intimidating terminology in there too... Right from the start we get things like \"Two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns).\" \n",
    "\n",
    "Here's the thing: in the [last notebook](https://raw.githubusercontent.com/kingsgeocomp/geocomputation/master/Practical-4-Functions%2C%20Packages%20and%20Methods.ipynb) we came close to inventing something a lot like pandas from scratch. \n",
    "\n",
    "So you already _know_ what's going on, or at least have an analogy that you can use to make sense of it. Pandas take a column-view of data in the same way that our Dictionary-of-Lists did, it's just got a lot more features to help you work with the data than our DoL does. That's why the documentation is so much more forbidding. And why pandas is so much more powerful.\n",
    "\n",
    "But at its heart, a pandas data frame ('df' for short) is just a collection of data series (i.e. columns) with an index. Each Series is like one of our column-lists from the last notebook. And the DataFrame is like the overarching dictionary that held the collection of data series (serieses?) together. OK? You've seen this before.\n",
    "\n",
    "Let's try it with last week's data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://www.reades.com/CitiesWithWikipediaData.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check it out!\n",
    "\n",
    "Instead of having to write a 'readRemoteCSV' function and then manually create a Dictionary-of-Lists from that remote file, we just told pandas to read it for us and it automagically converted it to a data structure that we could view. You'll notice that it even figured out where the column names were. \n",
    "\n",
    "All we head with `df.head()` was ask it to print out the first 5 rows of data. If we wanted to only see the first two rows it would be `df.head(2)`. This is pretty handy, right? \n",
    "\n",
    "Let's try a few more things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll probably have seen a fairly prominent warning (\"Invalid value encountered in percentile\"), and if you look closely you'll see that there are some fields that report things like '`NaN`' in some of the rows. These are related, but let's take a step back for a second: by calling the `describe` we were able to produce a 7-figure summary for _most_ of the columns in the data! That's a pretty handy way to summarise what's in there, right?\n",
    "\n",
    "So, just be calling `describe`...\n",
    "1. We've asked Python to describe the data frame and it has returned a set of columns with descriptive metrics for each.\n",
    "2. Note what is _missing_ from this list: where are 'Name', 'MetroArea', and a couple of the other columns? Can you think why they weren't reported in the descriptives?\n",
    "3. For the other columns, notice that `NaN`. `NaN` is short-hand for 'Not a Number' an it flags up a potential problem when we are dealing with numeric columns because it's hard to know what do with something like that in a column that should contain only numbers. Is something that isn't a number something that should be ignored? Is it a major problem? Is it a 'we don't know the value' or 'we couldn't read the value'? Those are different problems!\n",
    "\n",
    "Of course, maybe you don't want all of this, maybe you're just interested in one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.Population.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have the same information, but only for the Population column. We have to do this a _little_ differently because describing the DataFrame does some clever formatting, but describe a Series requires us to print out the result. Also notice that `dtype` at the end: that tells us the _data type_ is a 64-bit float. You can have strings, floats, integers, booleans, etc. in a DataFrame.\n",
    "\n",
    "But the really crucial thing is that this introduces _one_ of the two ways that we access a Series in pandas: `<data frame>.<series name>.method`. So we could get similar information on the Name column with:\n",
    "```python\n",
    "df.Name.describe()\n",
    "```\n",
    "And so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.Name.describe()\n",
    "print \" \"\n",
    "print \"The mean is: \" + str(df.Population.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that describing a text column gives us an 'object' data type because a String is a complex object, not a simple float or int.\n",
    "\n",
    "And notice to that we can ask for the a derived variable (such as the mean) just be asking the Series to do the work for us: `<data frame>.<series>.method()`. You might want to have a [look at the documentation](http://pandas.pydata.org/pandas-docs/stable/api.html#series) to see what other methods are available for a data series. It's rather a long list.\n",
    "\n",
    "### A Challenge for You!\n",
    "\n",
    "If all of this has made some kind of sense, why not spend a few minutes exploring the data using pandas. Why do you think that there are a large number of \"Unnamed\" columns with NaNs in them? Try looking at the data to see if you can figure it out... here's a clue: the equivalent of `myList[5]` in a DataFrame is...\n",
    "```python\n",
    "df.iloc[5]\n",
    "```\n",
    "Use the coding block below for your exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now that we've seen the _bare bones basics_ of pandas, let's start working with some real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Data\n",
    "\n",
    "One of the key things to do when working with any new data set is to familiarise yourself with it. You can do this in a variety of ways:\n",
    "* Read sources about the data, e.g. ONS (2010)\n",
    "* Review any accompanying metadata (data about the data)\n",
    "* Looking at the data itself, including comparing it to a) and b)\n",
    "* Make initial data analyses, including descriptive statistics \n",
    "* Visualize the data using plots \n",
    "In fact, you should use _all_ of these together to really understand where the data came from, how it was handled, and whether there are gaps or other problems.\n",
    "\n",
    "For the remainder of this module we're going to be working with two types of data: data about people (Socio-economic Classifcation) and data about the environment (weather). We've selected two very different types of data on purpose:\n",
    "1. Because we know that some of you have interests in the human environment, and others in the natural\n",
    "2. Because these are very different types of data with very different properties\n",
    "3. Because we'll see that _similar_ workflows can be used with each!\n",
    "What we want to highlight is that computational approaches are _highly transferrable_ between contexts. The mean or median is not _less_ relevant in one context than another, it's just more or less appropriate as a tool for understanding the data! \n",
    "\n",
    "### A Bit of Context\n",
    "\n",
    "The statistician George Box [once said](https://en.wikipedia.org/wiki/All_models_are_wrong) \"all models are wrong but some are useful\". Now you might think that 'wrong' _implies_ uselessness, but this aphorism is a lot more interesting than that: if you're following this course in-person, then you'll have come across the idea of statistics as the study of a 'data generating process'. \n",
    "\n",
    "The data that we work with is a _representation_ of reality, it is not reality itself. Just because I can say that the height of human beings is normally distributed with a mean of, say, 170cm and standard deviation of 8cm doesn't mean that I've _explained_ that process. What I have done is to say that reality can be reasonably well approximated by a normal distribution with those features. \n",
    "\n",
    "Given that understanding, I know that someone with a heigh of 2m is very, very improbable. Not impossible, just highly unlikely. So if I meet someone that tall then that's quite exciting! But my use of a normal distribution to represent that reality doesn't mean that I think that height is randomly distributed amongst all human beings like some gigantic lottery system: some parts of the world are typically shorter, other parts typcially taller. \n",
    "\n",
    "So the _real_ reason for someone's height is to do with, I assume, genetics and nutrition, but across large groups of people it's possible to _represent_ the cumulative impact of those individual realities with a simple normal distribution. And using that simplified data generating process allows me to do things like estimate the likelihood of meeting someone 2m tall (which is why I'd be excited to do so).\n",
    "\n",
    "In the same way, real individuals earn different incomes for all sorts of reasons: skills, education, negotiation ability... and systematic discrimination or bias. Because of wide variations in individual lived experience, it's quite hard to _prove_ that any _one_ person has been discriminated against unless you have the 'smoking gun' of an email or other direct evidence. \n",
    "\n",
    "But if I have data on _many_ men and women (from either inside or outside of the company) to work with, then I can take a look at what data generting processes best describe what I've observed. And I can also create a data generating process that would describe what I'd _expect_ if there were no discrimination taking place. \n",
    "\n",
    "And if I find a significant difference then I can start to rule out claims that 'there are no good candidates' and the other redoubts of the indefensible. It is _possible_ that a company had trouble finding qualified candidates, but as you put together the evidence using statistics it becomes increasingly _improbable_.\n",
    "\n",
    "So, always remember that the data is not reality. But it is a very useful abstraction of reality that allows us to search for larger patterns and to make certain claims about the observations in the data based on what we know about the characteristics of the data generating process.\n",
    "\n",
    "Here's a (slightly terrifying) video to explain this another way:\n",
    "\n",
    "[![From reality to make-believe](http://img.youtube.com/vi/HAfI0g_S9oo/0.jpg)](https://www.youtube.com/watch?v=HAfI0g_S9oo)\n",
    "\n",
    "### Socio-economic Classification Data\n",
    "\n",
    "Many governments publish large data sets drawn from a national Census that takes place every 5 or 10 years. And we know that things like education and income affect people's life chances in the long-run: higher levels of education, higher incomes, more senior jobs, and owning a house (instead of renting) tend to be linked to better health and other long-term advantages. \n",
    "\n",
    "So if we want to understand the overall distribution of these advantages in the population as a whole it might be handy to derive a 'class' for every household based on their levels of education, their job, their, health, and so forth. We can then look at how those classes are distributed across an area to see if there is mixing (generally thought to be a good thing) or to select an area for further investigation.\n",
    "\n",
    "In the UK this [classifcation](http://www.statistics.gov.uk/downloads/theme_compendia/ESRC_Review.pdf) is known as the National Statistics Socio-economic Classifcation (NS-SeC). You really should [read the documentation](http://webarchive.nationalarchives.gov.uk/20160105160709/http://www.ons.gov.uk/ons/guide-method/classifications/current-standard-classifications/soc2010/soc2010-volume-3-ns-sec--rebased-on-soc2010--user-manual/index.html) before trying to work with this data for research (or an end-of-term essay) but the main point is the 8-fold classifcation:\n",
    "\n",
    "| Analytic Class | Description |\n",
    "| --- | --- |\n",
    "| 1 | Higher managerial and professional occupations |\n",
    "| 2 | Lower managerial and professional occupations |\n",
    "| 3 | Intermediate occupations (clerical, sales, service) |\n",
    "| 4 | Small employers and own account workers |\n",
    "| 5 | Lower supervisory and technical occupations |\n",
    "| 6 | Semi-routine occupations |\n",
    "| 7 | Routine occupations |\n",
    "| 8 | Never worked or long-term unemployed |\n",
    "| NC | Not classified elsewhere |\n",
    "\n",
    "These can be grouped into a 3-fold classification:\n",
    "| Class | Description |\n",
    "| --- | --- |\n",
    "| 1 | Higher occupations |\n",
    "| 2 | Intermediate occupations |\n",
    "| 3 | Lower occupations |\n",
    "\n",
    "And they can also be disaggregated into more detailed groups a limited way.\n",
    "\n",
    "### Weather Data \n",
    "\n",
    "I've got a lot less to say about weather data at the moment because you've probably been making use of forecasts for much of your life! But it's still worth understanding something about how weather data is gathered and reported: many organisations operate weather stations where data on wind speed, temperature, rain, and amount of sun are collected and then transmitted to a server to be integrated into a larger data set of weather _observations_ at a national or global scale. Of course, any _one_ station might be in the 'wrong' place (somewhere shady or protected from the rain) or it might even break down, but the idea is that if you have enough of them you can collect a pretty good range of data for the country and begin to look for patterns and, potentially, make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Getting the NS-SeC Data\n",
    "\n",
    "## Using InFuse\n",
    "To obtain the NS-SeC data you'll have to visit the [InFuse](http://infuse.mimas.ac.uk) web site. Here's what you'll need to do:\n",
    "1. Select the 2011 Census data\n",
    "2. Scroll down the 'Filters' on the left-hand side of the page until you find 'NS-Sec' (*note*: there are _four_ options)\n",
    "3. Select the first NS-SeC filter: \"NS-SeC (National Statistics Socio-economic Classification) of household reference person\"\n",
    "4. Select the first option (Usual resident population; NS-SeC) from the range of data sets offered\n",
    "5. Read about the selected topic and then click 'Next'\n",
    "6. Select 'Total', classes 1–8, and Not classified using the checkboxes.\n",
    "7. Click 'Add' to add these to the 'Selected category combinations' below (it should say \"You have selected 10 category combinations)\n",
    "8. Click 'Next'\n",
    "9. Select 'Middle Super Output Areas' (8,480 areas) from the checkboxes and then click 'Add'\n",
    "10. Click 'Next', review the data extract information, and then click 'Get the data'\n",
    "11. When the big red 'Download the data' button appears after a few seconds click 'Download'\n",
    "12. Save the data to the _same folder_ as this notebook.\n",
    "\n",
    "If you've followed the steps above carefully, you should now have a Zip file showing in the 'Home' tab of your browser (the tab from which you launched this notebook).\n",
    "\n",
    "## Processing the data\n",
    "\n",
    "You could always unzip the downloaded file manually by double-clicking the zipfile, but given that we're programming in Python perhaps we could do it a different way?\n",
    "\n",
    "Perhaps [Google](http://www.google.com/) has the answer to 'unzipping zip files python'? And perhaps the first answer in that list will be something from [StackOverflow](http://stackoverflow.com/questions/3451111/unzipping-files-in-python)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = ???\n",
    "zip_ref.extractall('./Data/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all has gone well you should now have a folder called 'Data' inside the folder where this notebook sits. The Data folder contains three files:\n",
    "1. citations.rtf – this is information about how to reference this data set so that other people know where it came from. \n",
    "2. Data_NSSHRP_UNIT_URESPOP.csv – this looks promising...\n",
    "3. Meta_NSSHRP_UNIT_URESPOP.csv – this file takes a little getting used to but it's very, very important since it's the metadata that describes each column in our downloaded data file!\n",
    "\n",
    "The hardest thing about the metadata file is that several rows can relate to _one_ column in the data file. That's because each row is giving us _different_ information about what the column contains: what's it about, where did it come from, what format is it in? Etc.\n",
    "\n",
    "Let's be _bit_ naughty and just see what happens if we try to load the data file directly into pandas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDU_ID</th>\n",
       "      <th>GEO_CODE</th>\n",
       "      <th>GEO_LABEL</th>\n",
       "      <th>GEO_TYPE</th>\n",
       "      <th>GEO_TYP2</th>\n",
       "      <th>F2084</th>\n",
       "      <th>F2085</th>\n",
       "      <th>F2094</th>\n",
       "      <th>F2102</th>\n",
       "      <th>F2107</th>\n",
       "      <th>F2114</th>\n",
       "      <th>F2119</th>\n",
       "      <th>F2127</th>\n",
       "      <th>F2133</th>\n",
       "      <th>F2136</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9937.0</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>Middle Super Output Areas and Intermediate Zones</td>\n",
       "      <td>MSOAIZ</td>\n",
       "      <td>7187</td>\n",
       "      <td>2730</td>\n",
       "      <td>2246</td>\n",
       "      <td>543</td>\n",
       "      <td>497</td>\n",
       "      <td>224</td>\n",
       "      <td>308</td>\n",
       "      <td>212</td>\n",
       "      <td>178</td>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9938.0</td>\n",
       "      <td>E02000002</td>\n",
       "      <td>Barking and Dagenham 001</td>\n",
       "      <td>Middle Super Output Areas and Intermediate Zones</td>\n",
       "      <td>MSOAIZ</td>\n",
       "      <td>6724</td>\n",
       "      <td>340</td>\n",
       "      <td>1180</td>\n",
       "      <td>785</td>\n",
       "      <td>871</td>\n",
       "      <td>526</td>\n",
       "      <td>1276</td>\n",
       "      <td>963</td>\n",
       "      <td>589</td>\n",
       "      <td>194</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CDU_ID   GEO_CODE                 GEO_LABEL  \\\n",
       "0     NaN        NaN                       NaN   \n",
       "1  9937.0  E02000001        City of London 001   \n",
       "2  9938.0  E02000002  Barking and Dagenham 001   \n",
       "\n",
       "                                           GEO_TYPE GEO_TYP2  \\\n",
       "0                                               NaN      NaN   \n",
       "1  Middle Super Output Areas and Intermediate Zones   MSOAIZ   \n",
       "2  Middle Super Output Areas and Intermediate Zones   MSOAIZ   \n",
       "\n",
       "                                               F2084  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "1                                               7187   \n",
       "2                                               6724   \n",
       "\n",
       "                                               F2085  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "1                                               2730   \n",
       "2                                                340   \n",
       "\n",
       "                                               F2094  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "1                                               2246   \n",
       "2                                               1180   \n",
       "\n",
       "                                               F2102  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "1                                                543   \n",
       "2                                                785   \n",
       "\n",
       "                                               F2107  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "1                                                497   \n",
       "2                                                871   \n",
       "\n",
       "                                               F2114  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "1                                                224   \n",
       "2                                                526   \n",
       "\n",
       "                                               F2119  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "1                                                308   \n",
       "2                                               1276   \n",
       "\n",
       "                                               F2127  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "1                                                212   \n",
       "2                                                963   \n",
       "\n",
       "                                               F2133  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "1                                                178   \n",
       "2                                                589   \n",
       "\n",
       "                                               F2136  Unnamed: 15  \n",
       "0  NS-SeC (National Statistics Socio-economic Cla...          NaN  \n",
       "1                                                249          NaN  \n",
       "2                                                194          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./Data/Data_NSSHRP_UNIT_URESPOP.csv')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be pretty obvious that this isn't quite what we want: although we did get the variable names from the first row of the file, row 0 of our data frame still contains metadata! It's time to see what we can do in pandas to tidy this up _when_ we do the import.\n",
    "\n",
    "I'd suggest looking at the [pandas documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) for `read_csv`, and in particular at the following options that can be _passed_ to `read_csv()`:\n",
    "* header\n",
    "* names\n",
    "* usecols\n",
    "* skiprows\n",
    "* nrows\n",
    "\n",
    "By way of guidance:\n",
    "* I would _suggest_ that you skip the first couple of rows\n",
    "* I would _suggest_ that you drop (i.e. ignore) some of the columns \n",
    "* I would _suggest_ that you specify your own column names\n",
    "* I would _suggest_ that while you get this right you only read a small number of rows\n",
    "\n",
    "Answer at the end of this notebook, but try it yourself first by adding one parameter at a time to _build_ a working import statement (don't try all of these options at once!). But by way of a hint to get you started and to ensure that you end up with the same column names that I do:\n",
    "```python\n",
    "colnames = ['CDU','GeoCode','GeoLabel','GeoType','GeoType2','Total']\n",
    "for i in range(1,8):\n",
    "    colnames.append('Group' + str(i))\n",
    "colnames.append('NC')\n",
    "```\n",
    "Now over to you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've now written the components of a Python script that can take a file downloaded from InFuse, automatically extract the contents from a Zip archive, and then load the data into pandas automatically. Now that we've done it for _one_ file, we can work out how to do it for _any_ file. That's what we mean by scalability: yes, the column names will be different for other files downloaded from InFuse, but the _process_ is the same: we could create a function that handles all of this for us and the only thing it would need is the names that we want to use for the columns! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Getting Weather Data\n",
    "\n",
    "Now let's switch gear a bit. The UK's Met Office is a world-leading weather and climate research centre, and even if it doesn't always seem like their forecasts are very accurate that's because Britain's weather is inherently _unpredictable_. They've also done a lot of work to make their weather data widely available to people like us.\n",
    "\n",
    "But because the weather is changing all the time, so is the data! And, 'worse', it's becoming obsolete: the forecast from 2 years ago isn't particularly useful to us now. And asking for 'yesterday's weather' depends on the day that we're asking! When you have data in something like 'real-time' you don't normally access it the same way: you use something called an API (Application Programming Interface) that is designed with programmatic interaction in mind right from the start.\n",
    "\n",
    "Helpfully, the MetOffice provides a lot of documentation about their API (I'd suggest bookmarking it): http://www.metoffice.gov.uk/datapoint/support/api-reference\n",
    "\n",
    "This type of data requires a lot more research up front to work with, but it's very flexible once you know how it works because you can _customise_ the extract to obtain only the fields that you need instead of being 'stuck' with what the provider wants to give you.\n",
    "\n",
    "## Obtaining an API Key\n",
    "\n",
    "The first step to working with the API from the MetOffice is to obtain an API key: [do that here](http://www.metoffice.gov.uk/datapoint/API).\n",
    "\n",
    "## Making an API Request\n",
    "\n",
    "We then use the key as part of an API request: the process by which we _ask_ for data. We're going to show you the code and output first and then we'll talk through the steps involved. But, first, you'll need to replace \"???\" with the API key provided to you by the MetOffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://datapoint.metoffice.gov.uk/public/data/val/wxobs/all/json/3772?res=hourly&key=f997090f-8b2a-444e-8ceb-260f07094eb1\n",
      "{u'SiteRep': {u'DV': {u'type': u'Obs', u'dataDate': u'2016-09-09T12:00:00Z', u'Location': {u'elevation': u'25.0', u'name': u'HEATHROW', u'i': u'3772', u'country': u'ENGLAND', u'lon': u'-0.4491', u'Period': [{u'Rep': [{u'D': u'WSW', u'Pt': u'R', u'H': u'44.2', u'P': u'1011', u'S': u'19', u'T': u'23.2', u'W': u'1', u'V': u'30000', u'Dp': u'10.4', u'$': u'720'}, {u'D': u'WSW', u'Pt': u'R', u'H': u'43.3', u'P': u'1012', u'S': u'18', u'T': u'23.3', u'W': u'1', u'V': u'15000', u'Dp': u'10.2', u'$': u'780'}, {u'D': u'W', u'Pt': u'R', u'H': u'45.2', u'P': u'1012', u'S': u'16', u'T': u'22.8', u'W': u'7', u'V': u'30000', u'Dp': u'10.4', u'$': u'840'}, {u'D': u'W', u'G': u'29', u'Dp': u'10.5', u'H': u'46.0', u'P': u'1012', u'S': u'16', u'T': u'22.6', u'W': u'7', u'V': u'30000', u'Pt': u'R', u'$': u'900'}, {u'D': u'W', u'Pt': u'R', u'H': u'46.4', u'P': u'1012', u'S': u'14', u'T': u'22.7', u'W': u'3', u'V': u'40000', u'Dp': u'10.7', u'$': u'960'}, {u'D': u'W', u'Pt': u'R', u'H': u'47.7', u'P': u'1013', u'S': u'15', u'T': u'21.8', u'W': u'1', u'V': u'40000', u'Dp': u'10.3', u'$': u'1020'}, {u'D': u'W', u'Pt': u'R', u'H': u'47.8', u'P': u'1013', u'S': u'15', u'T': u'20.8', u'W': u'1', u'V': u'45000', u'Dp': u'9.4', u'$': u'1080'}, {u'D': u'WSW', u'Pt': u'R', u'H': u'53.9', u'P': u'1014', u'S': u'9', u'T': u'19.4', u'W': u'0', u'V': u'40000', u'Dp': u'9.9', u'$': u'1140'}, {u'D': u'SW', u'Pt': u'R', u'H': u'64.3', u'P': u'1015', u'S': u'11', u'T': u'18.4', u'W': u'0', u'V': u'21000', u'Dp': u'11.6', u'$': u'1200'}, {u'D': u'SW', u'Pt': u'R', u'H': u'70.4', u'P': u'1015', u'S': u'11', u'T': u'17.2', u'W': u'0', u'V': u'19000', u'Dp': u'11.8', u'$': u'1260'}, {u'D': u'SSW', u'Pt': u'R', u'H': u'74.1', u'P': u'1015', u'S': u'9', u'T': u'16.5', u'W': u'0', u'V': u'19000', u'Dp': u'11.9', u'$': u'1320'}, {u'D': u'S', u'Pt': u'R', u'H': u'79.5', u'P': u'1015', u'S': u'6', u'T': u'15.6', u'W': u'7', u'V': u'18000', u'Dp': u'12.1', u'$': u'1380'}], u'type': u'Day', u'value': u'2016-09-08Z'}, {u'Rep': [{u'D': u'S', u'Pt': u'R', u'H': u'84.4', u'P': u'1015', u'S': u'8', u'T': u'15.6', u'W': u'2', u'V': u'15000', u'Dp': u'13.0', u'$': u'0'}, {u'D': u'S', u'Pt': u'R', u'H': u'84.5', u'P': u'1015', u'S': u'8', u'T': u'15.8', u'W': u'7', u'V': u'15000', u'Dp': u'13.2', u'$': u'60'}, {u'D': u'S', u'Pt': u'F', u'H': u'83.9', u'P': u'1015', u'S': u'8', u'T': u'16.3', u'W': u'7', u'V': u'16000', u'Dp': u'13.6', u'$': u'120'}, {u'D': u'S', u'Pt': u'F', u'H': u'80.8', u'P': u'1015', u'S': u'10', u'T': u'17.0', u'W': u'7', u'V': u'17000', u'Dp': u'13.7', u'$': u'180'}, {u'D': u'SSW', u'Pt': u'F', u'H': u'83.0', u'P': u'1015', u'S': u'13', u'T': u'17.0', u'W': u'8', u'V': u'20000', u'Dp': u'14.1', u'$': u'240'}, {u'D': u'SSW', u'Pt': u'F', u'H': u'87.9', u'P': u'1015', u'S': u'10', u'T': u'16.7', u'W': u'8', u'V': u'21000', u'Dp': u'14.7', u'$': u'300'}, {u'D': u'SSW', u'Pt': u'R', u'H': u'87.4', u'P': u'1015', u'S': u'9', u'T': u'17.3', u'W': u'7', u'V': u'40000', u'Dp': u'15.2', u'$': u'360'}, {u'D': u'SSW', u'Pt': u'R', u'H': u'85.2', u'P': u'1015', u'S': u'10', u'T': u'17.7', u'W': u'7', u'V': u'40000', u'Dp': u'15.2', u'$': u'420'}, {u'D': u'SSW', u'Pt': u'R', u'H': u'84.3', u'P': u'1015', u'S': u'9', u'T': u'19.3', u'W': u'8', u'V': u'24000', u'Dp': u'16.6', u'$': u'480'}, {u'D': u'SSW', u'Pt': u'R', u'H': u'73.7', u'P': u'1015', u'S': u'11', u'T': u'19.8', u'W': u'8', u'V': u'29000', u'Dp': u'15.0', u'$': u'540'}, {u'D': u'S', u'Pt': u'R', u'H': u'61.7', u'P': u'1015', u'S': u'13', u'T': u'23.0', u'W': u'7', u'V': u'27000', u'Dp': u'15.3', u'$': u'600'}, {u'D': u'S', u'Pt': u'F', u'H': u'58.5', u'P': u'1014', u'S': u'17', u'T': u'22.8', u'W': u'3', u'V': u'14000', u'Dp': u'14.3', u'$': u'660'}, {u'D': u'SSW', u'Pt': u'F', u'H': u'58.3', u'P': u'1014', u'S': u'15', u'T': u'23.2', u'W': u'7', u'V': u'28000', u'Dp': u'14.6', u'$': u'720'}], u'type': u'Day', u'value': u'2016-09-09Z'}], u'lat': u'51.479', u'continent': u'EUROPE'}}, u'Wx': {u'Param': [{u'units': u'mph', u'name': u'G', u'$': u'Wind Gust'}, {u'units': u'C', u'name': u'T', u'$': u'Temperature'}, {u'units': u'm', u'name': u'V', u'$': u'Visibility'}, {u'units': u'compass', u'name': u'D', u'$': u'Wind Direction'}, {u'units': u'mph', u'name': u'S', u'$': u'Wind Speed'}, {u'units': u'', u'name': u'W', u'$': u'Weather Type'}, {u'units': u'hpa', u'name': u'P', u'$': u'Pressure'}, {u'units': u'Pa/s', u'name': u'Pt', u'$': u'Pressure Tendency'}, {u'units': u'C', u'name': u'Dp', u'$': u'Dew Point'}, {u'units': u'%', u'name': u'H', u'$': u'Screen Relative Humidity'}]}}}\n"
     ]
    }
   ],
   "source": [
    "import json, requests\n",
    "\n",
    "api_key   = \"???\" # your API key\n",
    "api_url   = \"http://datapoint.metoffice.gov.uk/public/data/\" # base URL\n",
    "obs_json  = \"val/wxobs/all/json/\" # observations URL\n",
    "fcs_json  = \"val/wxfcs/all/json/\" # forecasts URL\n",
    "\n",
    "heathrow = str(3772)  # heathrow airport weather station\n",
    "\n",
    "payload = {'res': 'hourly', 'key': api_key}\n",
    "r = requests.get(api_url + obs_json + heathrow, params=payload)\n",
    "\n",
    "#check the call - need some proper try, except stuff here\n",
    "print(r.url)\n",
    "\n",
    "#check the output\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now let's make sense of this:\n",
    "```python\n",
    "import json, requests\n",
    "\n",
    "api_key   = \"???\" # your API key\n",
    "api_url   = \"http://datapoint.metoffice.gov.uk/public/data/\" # base URL\n",
    "obs_json  = \"val/wxobs/all/json/\" # observations URL\n",
    "fcs_json  = \"val/wxfcs/all/json/\" # forecasts URL\n",
    "```\n",
    "So, first we import two new modules: one that makes requests to a web server, and one that will parse JSON responses from the server in order to turn them into something that we can use.\n",
    "\n",
    "Then we set up some default values that will allow us to build our request to the MetOffice server. The comments help us to remember what each of these variables is.\n",
    "\n",
    "Now let's do the actual work:\n",
    "```python\n",
    "heathrow = str(3772)  # heathrow airport weather station\n",
    "\n",
    "payload = {'res': 'hourly', 'key': api_key}\n",
    "r = requests.get(api_url + obs_json + heathrow, params=payload)\n",
    "\n",
    "# Check the call - need some proper try, except stuff here\n",
    "print(r.url)\n",
    "\n",
    "# Check the output\n",
    "print(r.json())\n",
    "```\n",
    "We want the data for Heathrow Airport: we have to request it using a unique identifier (3772 in this case) because that's easier for the computer to handle than a long, potentially ambiguous string. For instance, if you asked for 'London' what would you get? The City of London? Greater London? \n",
    "\n",
    "We can then assemble a URL request by combining the site name, the observations URL, and the parameters. In this case that's: the type of 'resource' (the hourly observations), and our API key.\n",
    "\n",
    "The last two steps are just about printing out the reply... It's pretty hard to figure out what that reply means, but it's actually just a kind of dictionary. That's it. It looks like a mess, but it _is_ a dictionary and the only thing that is entirely new is the fact that every string has the letter 'u' in front of it. That 'u' means 'Unicode' and it just a kind of string...\n",
    "\n",
    "It might be a little easier to read if we just look at the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'Param': [{u'units': u'mph', u'name': u'G', u'$': u'Wind Gust'}, {u'units': u'C', u'name': u'T', u'$': u'Temperature'}, {u'units': u'm', u'name': u'V', u'$': u'Visibility'}, {u'units': u'compass', u'name': u'D', u'$': u'Wind Direction'}, {u'units': u'mph', u'name': u'S', u'$': u'Wind Speed'}, {u'units': u'', u'name': u'W', u'$': u'Weather Type'}, {u'units': u'hpa', u'name': u'P', u'$': u'Pressure'}, {u'units': u'Pa/s', u'name': u'Pt', u'$': u'Pressure Tendency'}, {u'units': u'C', u'name': u'Dp', u'$': u'Dew Point'}, {u'units': u'%', u'name': u'H', u'$': u'Screen Relative Humidity'}]}\n"
     ]
    }
   ],
   "source": [
    "pdesc = r.json()['SiteRep']['Wx']\n",
    "pdat  = r.json()['SiteRep']['DV']\n",
    "\n",
    "print(pdesc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the above also looks a lot like a mix of Python dictionaries and lists: '{' and '['.\n",
    "\n",
    "Let's reformat it a bit using _recursion_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dKey: Param\n",
      "\t\tdKey: units\n",
      "\t\tdValue: mph\n",
      "\t\tdKey: name\n",
      "\t\tdValue: G\n",
      "\t\tdKey: $\n",
      "\t\tdValue: Wind Gust\n",
      "\n",
      "\n",
      "\t\tdKey: units\n",
      "\t\tdValue: C\n",
      "\t\tdKey: name\n",
      "\t\tdValue: T\n",
      "\t\tdKey: $\n",
      "\t\tdValue: Temperature\n",
      "\n",
      "\n",
      "\t\tdKey: units\n",
      "\t\tdValue: m\n",
      "\t\tdKey: name\n",
      "\t\tdValue: V\n",
      "\t\tdKey: $\n",
      "\t\tdValue: Visibility\n",
      "\n",
      "\n",
      "\t\tdKey: units\n",
      "\t\tdValue: compass\n",
      "\t\tdKey: name\n",
      "\t\tdValue: D\n",
      "\t\tdKey: $\n",
      "\t\tdValue: Wind Direction\n",
      "\n",
      "\n",
      "\t\tdKey: units\n",
      "\t\tdValue: mph\n",
      "\t\tdKey: name\n",
      "\t\tdValue: S\n",
      "\t\tdKey: $\n",
      "\t\tdValue: Wind Speed\n",
      "\n",
      "\n",
      "\t\tdKey: units\n",
      "\t\tdValue: \n",
      "\t\tdKey: name\n",
      "\t\tdValue: W\n",
      "\t\tdKey: $\n",
      "\t\tdValue: Weather Type\n",
      "\n",
      "\n",
      "\t\tdKey: units\n",
      "\t\tdValue: hpa\n",
      "\t\tdKey: name\n",
      "\t\tdValue: P\n",
      "\t\tdKey: $\n",
      "\t\tdValue: Pressure\n",
      "\n",
      "\n",
      "\t\tdKey: units\n",
      "\t\tdValue: Pa/s\n",
      "\t\tdKey: name\n",
      "\t\tdValue: Pt\n",
      "\t\tdKey: $\n",
      "\t\tdValue: Pressure Tendency\n",
      "\n",
      "\n",
      "\t\tdKey: units\n",
      "\t\tdValue: C\n",
      "\t\tdKey: name\n",
      "\t\tdValue: Dp\n",
      "\t\tdKey: $\n",
      "\t\tdValue: Dew Point\n",
      "\n",
      "\n",
      "\t\tdKey: units\n",
      "\t\tdValue: %\n",
      "\t\tdKey: name\n",
      "\t\tdValue: H\n",
      "\t\tdKey: $\n",
      "\t\tdValue: Screen Relative Humidity\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def outputList(l, depth): \n",
    "    for i in range(len(l)):\n",
    "        value = l[i]\n",
    "        if type(value) is list:\n",
    "            outputList(value, depth+1)\n",
    "        elif type(value) is dict: \n",
    "            outputDict(value, depth+1)\n",
    "        else:\n",
    "            print \"\\t\" * depth + \"lValue: \" + value\n",
    "    print \"\\n\"\n",
    "\n",
    "def outputDict(d, depth):\n",
    "    for key, value in d.iteritems():\n",
    "        print \"\\t\" * depth + \"dKey: \" + key\n",
    "        if type(value) is list:\n",
    "            outputList(value, depth+1)\n",
    "        elif type(value) is dict:\n",
    "            outputDict(value, depth+1)\n",
    "        else:\n",
    "            print \"\\t\" * depth + \"dValue: \" + value\n",
    "    print \"\\n\"\n",
    "\n",
    "outputDict(pdesc, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wouldn't get too hung up on how recursion works, but it's a _very_ powerful concept: in this case we know that we're starting with a dictionary so we ask `outputDict` to start outputting the content of `pdesc` (the rePly DESCription). `outputDict` then takes each of the key/value pairs in turn, looks at the value to see if _it_ is a dictionary or list or (by default) string and takes appropriate action. We've also got an `outputList` function that does the same thing: it looks at the elements of the list and either prints out the item or passes it back to a function to process further. As I said, don't get too stressed out if it doesn't make sense just yet, but it's worth gradually getting to grips with it.\n",
    "\n",
    "We can do the same with the data in the reply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dKey: type\n",
      "dValue: Obs\n",
      "dKey: dataDate\n",
      "dValue: 2016-09-09T12:00:00Z\n",
      "dKey: Location\n",
      "\tdKey: elevation\n",
      "\tdValue: 25.0\n",
      "\tdKey: name\n",
      "\tdValue: HEATHROW\n",
      "\tdKey: i\n",
      "\tdValue: 3772\n",
      "\tdKey: country\n",
      "\tdValue: ENGLAND\n",
      "\tdKey: lon\n",
      "\tdValue: -0.4491\n",
      "\tdKey: Period\n",
      "\t\t\tdKey: Rep\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: WSW\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 44.2\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1011\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 19\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 23.2\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 1\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 30000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 10.4\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 720\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: WSW\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 43.3\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1012\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 18\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 23.3\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 1\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 15000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 10.2\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 780\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: W\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 45.2\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1012\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 16\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 22.8\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 7\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 30000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 10.4\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 840\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: W\n",
      "\t\t\t\t\tdKey: G\n",
      "\t\t\t\t\tdValue: 29\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 10.5\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 46.0\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1012\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 16\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 22.6\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 7\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 30000\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 900\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: W\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 46.4\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1012\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 14\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 22.7\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 3\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 40000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 10.7\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 960\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: W\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 47.7\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1013\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 15\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 21.8\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 1\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 40000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 10.3\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 1020\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: W\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 47.8\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1013\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 15\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 20.8\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 1\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 45000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 9.4\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 1080\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: WSW\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 53.9\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1014\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 9\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 19.4\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 0\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 40000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 9.9\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 1140\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: SW\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 64.3\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 11\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 18.4\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 0\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 21000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 11.6\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 1200\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: SW\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 70.4\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 11\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 17.2\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 0\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 19000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 11.8\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 1260\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: SSW\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 74.1\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 9\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 16.5\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 0\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 19000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 11.9\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 1320\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: S\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 79.5\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 6\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 15.6\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 7\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 18000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 12.1\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 1380\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\tdKey: type\n",
      "\t\t\tdValue: Day\n",
      "\t\t\tdKey: value\n",
      "\t\t\tdValue: 2016-09-08Z\n",
      "\n",
      "\n",
      "\t\t\tdKey: Rep\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: S\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 84.4\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 8\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 15.6\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 2\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 15000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 13.0\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 0\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: S\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 84.5\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 8\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 15.8\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 7\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 15000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 13.2\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 60\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: S\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: F\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 83.9\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 8\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 16.3\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 7\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 16000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 13.6\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 120\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: S\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: F\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 80.8\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 10\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 17.0\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 7\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 17000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 13.7\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 180\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: SSW\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: F\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 83.0\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 13\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 17.0\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 8\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 20000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 14.1\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 240\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: SSW\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: F\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 87.9\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 10\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 16.7\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 8\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 21000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 14.7\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 300\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: SSW\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 87.4\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 9\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 17.3\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 7\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 40000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 15.2\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 360\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: SSW\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 85.2\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 10\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 17.7\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 7\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 40000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 15.2\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 420\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: SSW\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 84.3\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 9\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 19.3\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 8\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 24000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 16.6\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 480\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: SSW\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 73.7\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 11\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 19.8\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 8\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 29000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 15.0\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 540\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: S\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: R\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 61.7\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1015\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 13\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 23.0\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 7\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 27000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 15.3\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 600\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: S\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: F\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 58.5\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1014\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 17\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 22.8\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 3\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 14000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 14.3\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 660\n",
      "\n",
      "\n",
      "\t\t\t\t\tdKey: D\n",
      "\t\t\t\t\tdValue: SSW\n",
      "\t\t\t\t\tdKey: Pt\n",
      "\t\t\t\t\tdValue: F\n",
      "\t\t\t\t\tdKey: H\n",
      "\t\t\t\t\tdValue: 58.3\n",
      "\t\t\t\t\tdKey: P\n",
      "\t\t\t\t\tdValue: 1014\n",
      "\t\t\t\t\tdKey: S\n",
      "\t\t\t\t\tdValue: 15\n",
      "\t\t\t\t\tdKey: T\n",
      "\t\t\t\t\tdValue: 23.2\n",
      "\t\t\t\t\tdKey: W\n",
      "\t\t\t\t\tdValue: 7\n",
      "\t\t\t\t\tdKey: V\n",
      "\t\t\t\t\tdValue: 28000\n",
      "\t\t\t\t\tdKey: Dp\n",
      "\t\t\t\t\tdValue: 14.6\n",
      "\t\t\t\t\tdKey: $\n",
      "\t\t\t\t\tdValue: 720\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\tdKey: type\n",
      "\t\t\tdValue: Day\n",
      "\t\t\tdKey: value\n",
      "\t\t\tdValue: 2016-09-09Z\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tdKey: lat\n",
      "\tdValue: 51.479\n",
      "\tdKey: continent\n",
      "\tdValue: EUROPE\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputDict(pdat, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=2016, tm_mon=9, tm_mday=9, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=4, tm_yday=253, tm_isdst=-1)\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "if pdat['type'] != \"Obs\":\n",
    "    print(\"Errrr, these aren't observations!:\")\n",
    "\n",
    "# Ignore the time part as we're getting data with values in minutes\n",
    "# after midnight so we want to reset this to 00:00:00Z\n",
    "obsDate = time.strptime(pdat['dataDate'].split(\"T\")[0],'%Y-%m-%d')\n",
    "\n",
    "print obsDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 locations to process...\n",
      "{u'elevation': u'25.0', u'name': u'HEATHROW', u'i': u'3772', u'country': u'ENGLAND', u'lon': u'-0.4491', u'Period': [{u'Rep': [{u'D': u'WSW', u'Pt': u'R', u'H': u'44.2', u'P': u'1011', u'S': u'19', u'T': u'23.2', u'W': u'1', u'V': u'30000', u'Dp': u'10.4', u'$': u'720'}, {u'D': u'WSW', u'Pt': u'R', u'H': u'43.3', u'P': u'1012', u'S': u'18', u'T': u'23.3', u'W': u'1', u'V': u'15000', u'Dp': u'10.2', u'$': u'780'}, {u'D': u'W', u'Pt': u'R', u'H': u'45.2', u'P': u'1012', u'S': u'16', u'T': u'22.8', u'W': u'7', u'V': u'30000', u'Dp': u'10.4', u'$': u'840'}, {u'D': u'W', u'G': u'29', u'Dp': u'10.5', u'H': u'46.0', u'P': u'1012', u'S': u'16', u'T': u'22.6', u'W': u'7', u'V': u'30000', u'Pt': u'R', u'$': u'900'}, {u'D': u'W', u'Pt': u'R', u'H': u'46.4', u'P': u'1012', u'S': u'14', u'T': u'22.7', u'W': u'3', u'V': u'40000', u'Dp': u'10.7', u'$': u'960'}, {u'D': u'W', u'Pt': u'R', u'H': u'47.7', u'P': u'1013', u'S': u'15', u'T': u'21.8', u'W': u'1', u'V': u'40000', u'Dp': u'10.3', u'$': u'1020'}, {u'D': u'W', u'Pt': u'R', u'H': u'47.8', u'P': u'1013', u'S': u'15', u'T': u'20.8', u'W': u'1', u'V': u'45000', u'Dp': u'9.4', u'$': u'1080'}, {u'D': u'WSW', u'Pt': u'R', u'H': u'53.9', u'P': u'1014', u'S': u'9', u'T': u'19.4', u'W': u'0', u'V': u'40000', u'Dp': u'9.9', u'$': u'1140'}, {u'D': u'SW', u'Pt': u'R', u'H': u'64.3', u'P': u'1015', u'S': u'11', u'T': u'18.4', u'W': u'0', u'V': u'21000', u'Dp': u'11.6', u'$': u'1200'}, {u'D': u'SW', u'Pt': u'R', u'H': u'70.4', u'P': u'1015', u'S': u'11', u'T': u'17.2', u'W': u'0', u'V': u'19000', u'Dp': u'11.8', u'$': u'1260'}, {u'D': u'SSW', u'Pt': u'R', u'H': u'74.1', u'P': u'1015', u'S': u'9', u'T': u'16.5', u'W': u'0', u'V': u'19000', u'Dp': u'11.9', u'$': u'1320'}, {u'D': u'S', u'Pt': u'R', u'H': u'79.5', u'P': u'1015', u'S': u'6', u'T': u'15.6', u'W': u'7', u'V': u'18000', u'Dp': u'12.1', u'$': u'1380'}], u'type': u'Day', u'value': u'2016-09-08Z'}, {u'Rep': [{u'D': u'S', u'Pt': u'R', u'H': u'84.4', u'P': u'1015', u'S': u'8', u'T': u'15.6', u'W': u'2', u'V': u'15000', u'Dp': u'13.0', u'$': u'0'}, {u'D': u'S', u'Pt': u'R', u'H': u'84.5', u'P': u'1015', u'S': u'8', u'T': u'15.8', u'W': u'7', u'V': u'15000', u'Dp': u'13.2', u'$': u'60'}, {u'D': u'S', u'Pt': u'F', u'H': u'83.9', u'P': u'1015', u'S': u'8', u'T': u'16.3', u'W': u'7', u'V': u'16000', u'Dp': u'13.6', u'$': u'120'}, {u'D': u'S', u'Pt': u'F', u'H': u'80.8', u'P': u'1015', u'S': u'10', u'T': u'17.0', u'W': u'7', u'V': u'17000', u'Dp': u'13.7', u'$': u'180'}, {u'D': u'SSW', u'Pt': u'F', u'H': u'83.0', u'P': u'1015', u'S': u'13', u'T': u'17.0', u'W': u'8', u'V': u'20000', u'Dp': u'14.1', u'$': u'240'}, {u'D': u'SSW', u'Pt': u'F', u'H': u'87.9', u'P': u'1015', u'S': u'10', u'T': u'16.7', u'W': u'8', u'V': u'21000', u'Dp': u'14.7', u'$': u'300'}, {u'D': u'SSW', u'Pt': u'R', u'H': u'87.4', u'P': u'1015', u'S': u'9', u'T': u'17.3', u'W': u'7', u'V': u'40000', u'Dp': u'15.2', u'$': u'360'}, {u'D': u'SSW', u'Pt': u'R', u'H': u'85.2', u'P': u'1015', u'S': u'10', u'T': u'17.7', u'W': u'7', u'V': u'40000', u'Dp': u'15.2', u'$': u'420'}, {u'D': u'SSW', u'Pt': u'R', u'H': u'84.3', u'P': u'1015', u'S': u'9', u'T': u'19.3', u'W': u'8', u'V': u'24000', u'Dp': u'16.6', u'$': u'480'}, {u'D': u'SSW', u'Pt': u'R', u'H': u'73.7', u'P': u'1015', u'S': u'11', u'T': u'19.8', u'W': u'8', u'V': u'29000', u'Dp': u'15.0', u'$': u'540'}, {u'D': u'S', u'Pt': u'R', u'H': u'61.7', u'P': u'1015', u'S': u'13', u'T': u'23.0', u'W': u'7', u'V': u'27000', u'Dp': u'15.3', u'$': u'600'}, {u'D': u'S', u'Pt': u'F', u'H': u'58.5', u'P': u'1014', u'S': u'17', u'T': u'22.8', u'W': u'3', u'V': u'14000', u'Dp': u'14.3', u'$': u'660'}, {u'D': u'SSW', u'Pt': u'F', u'H': u'58.3', u'P': u'1014', u'S': u'15', u'T': u'23.2', u'W': u'7', u'V': u'28000', u'Dp': u'14.6', u'$': u'720'}], u'type': u'Day', u'value': u'2016-09-09Z'}], u'lat': u'51.479', u'continent': u'EUROPE'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-15f9b477abf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Get the location data and separate it from the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# observation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mlocID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     locations.append([locID, loc['name'].title(), loc['country'].title(), loc['continent'].title(), \n\u001b[1;32m     18\u001b[0m         float(loc['lat']), float(loc['lon']), float(loc['elevation']) ])\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# Count number of locations to process\n",
    "print(\"There are {0} locations to process...\".format(len(pdat['Location'])))\n",
    "\n",
    "locations = list()\n",
    "locations.append(['ID','Name','Country','Continent','Latitude','Longitude','Elevation'])\n",
    "\n",
    "observations = list()\n",
    "observations.append(['ID','Time','WeatherType','Visibility','Temperature','WindDirection',\n",
    "    'WindSpeed','WindGust','PressureTendency','DewPoint','Humidity'])\n",
    "\n",
    "print pdat['Location']\n",
    "\n",
    "for loc in pdat['Location']:\n",
    "    # Get the location data and separate it from the \n",
    "    # observation data\n",
    "    locID = int(loc['i'])\n",
    "    locations.append([locID, loc['name'].title(), loc['country'].title(), loc['continent'].title(), \n",
    "        float(loc['lat']), float(loc['lon']), float(loc['elevation']) ])\n",
    "        \n",
    "    # Now deal with the actual observations\n",
    "    for obs in loc['Period']: \n",
    "        if obs['type'] != 'Day' and str(obs['value']) != time.strftime(\"%Y-%m-%dZ\", obsDate):\n",
    "            print(\"Something has gone a bit wrong: either observation type is not day, or observation value is not the same as the file's\")\n",
    "            break\n",
    "        for report in obs['Rep']:\n",
    "            minutes_after_midnight = int(report['$'])\n",
    "            ts = dt.datetime.fromtimestamp(time.mktime(obsDate)) + dt.timedelta(0, minutes_after_midnight*60)\n",
    "            \n",
    "            for key in ['D','Pt']:\n",
    "                if key not in report:\n",
    "                    report[key] = u\"\"\n",
    "            for key in ['W','V','S','G']:\n",
    "                if key not in report or report[key] == \"\":\n",
    "                    report[key] = \"0\"\n",
    "            for key in ['T','Dp','H']:\n",
    "                if key not in report or report[key] == \"\":\n",
    "                    report[key] = \"0.0\"          \n",
    "            \n",
    "            observations.append([ locID, str(ts), int(report['W']), int(report['V']), float(report['T']), str(report['D']), \n",
    "                int(report['S']), int(report['G']), str(report['Pt']), float(report['Dp']), float(report['H']) ])\n",
    "\n",
    "print observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write CSV of Locations\n",
    "fn = \"-\".join([\"scope\", scope, \"obs\", str(dt.date.today()), 'locations']) + \".csv\"\n",
    "with open(os.path.join(path, fn), 'wb') as fh:\n",
    "    writer = csv.writer(fh)\n",
    "    writer.writerows(locations)\n",
    "\n",
    "# Write CSV of Observations\n",
    "fn = \"-\".join([\"scope\", scope, \"obs\", str(dt.date.today()), 'observations']) + \".csv\"\n",
    "with open(os.path.join(path, fn), 'wb') as fh:\n",
    "    writer = csv.writer(fh)\n",
    "    writer.writerows(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 1: Building a read_csv() Call for Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDU_ID</th>\n",
       "      <th>GEO_CODE</th>\n",
       "      <th>GEO_LABEL</th>\n",
       "      <th>GEO_TYPE</th>\n",
       "      <th>GEO_TYP2</th>\n",
       "      <th>F2084</th>\n",
       "      <th>F2085</th>\n",
       "      <th>F2094</th>\n",
       "      <th>F2102</th>\n",
       "      <th>F2107</th>\n",
       "      <th>F2114</th>\n",
       "      <th>F2119</th>\n",
       "      <th>F2127</th>\n",
       "      <th>F2133</th>\n",
       "      <th>F2136</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NS-SeC (National Statistics Socio-economic Cla...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CDU_ID  GEO_CODE  GEO_LABEL  GEO_TYPE  GEO_TYP2  \\\n",
       "0     NaN       NaN        NaN       NaN       NaN   \n",
       "\n",
       "                                               F2084  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "\n",
       "                                               F2085  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "\n",
       "                                               F2094  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "\n",
       "                                               F2102  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "\n",
       "                                               F2107  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "\n",
       "                                               F2114  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "\n",
       "                                               F2119  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "\n",
       "                                               F2127  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "\n",
       "                                               F2133  \\\n",
       "0  NS-SeC (National Statistics Socio-economic Cla...   \n",
       "\n",
       "                                               F2136  Unnamed: 15  \n",
       "0  NS-SeC (National Statistics Socio-economic Cla...          NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =======================\n",
    "# Building a more complex read_csv call\n",
    "# to import the NS-SeC Data\n",
    "# =======================\n",
    "df = pd.read_csv('./Data/Data_NSSHRP_UNIT_URESPOP.csv', nrows=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDU_ID</th>\n",
       "      <th>GEO_CODE</th>\n",
       "      <th>GEO_LABEL</th>\n",
       "      <th>GEO_TYPE</th>\n",
       "      <th>GEO_TYP2</th>\n",
       "      <th>F2084</th>\n",
       "      <th>F2085</th>\n",
       "      <th>F2094</th>\n",
       "      <th>F2102</th>\n",
       "      <th>F2107</th>\n",
       "      <th>F2114</th>\n",
       "      <th>F2119</th>\n",
       "      <th>F2127</th>\n",
       "      <th>F2133</th>\n",
       "      <th>F2136</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9937</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>Middle Super Output Areas and Intermediate Zones</td>\n",
       "      <td>MSOAIZ</td>\n",
       "      <td>7187</td>\n",
       "      <td>2730</td>\n",
       "      <td>2246</td>\n",
       "      <td>543</td>\n",
       "      <td>497</td>\n",
       "      <td>224</td>\n",
       "      <td>308</td>\n",
       "      <td>212</td>\n",
       "      <td>178</td>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CDU_ID   GEO_CODE           GEO_LABEL  \\\n",
       "0    9937  E02000001  City of London 001   \n",
       "\n",
       "                                           GEO_TYPE GEO_TYP2  F2084  F2085  \\\n",
       "0  Middle Super Output Areas and Intermediate Zones   MSOAIZ   7187   2730   \n",
       "\n",
       "   F2094  F2102  F2107  F2114  F2119  F2127  F2133  F2136  Unnamed: 15  \n",
       "0   2246    543    497    224    308    212    178    249          NaN  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/Data_NSSHRP_UNIT_URESPOP.csv', nrows=1, skiprows=[1])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CDU</th>\n",
       "      <th>GeoCode</th>\n",
       "      <th>GeoLabel</th>\n",
       "      <th>GeoType</th>\n",
       "      <th>GeoType2</th>\n",
       "      <th>Total</th>\n",
       "      <th>Group1</th>\n",
       "      <th>Group2</th>\n",
       "      <th>Group3</th>\n",
       "      <th>Group4</th>\n",
       "      <th>Group5</th>\n",
       "      <th>Group6</th>\n",
       "      <th>Group7</th>\n",
       "      <th>NC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9937</th>\n",
       "      <th>E02000001</th>\n",
       "      <td>City of London 001</td>\n",
       "      <td>Middle Super Output Areas and Intermediate Zones</td>\n",
       "      <td>MSOAIZ</td>\n",
       "      <td>7187</td>\n",
       "      <td>2730</td>\n",
       "      <td>2246</td>\n",
       "      <td>543</td>\n",
       "      <td>497</td>\n",
       "      <td>224</td>\n",
       "      <td>308</td>\n",
       "      <td>212</td>\n",
       "      <td>178</td>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9938</th>\n",
       "      <th>E02000002</th>\n",
       "      <td>Barking and Dagenham 001</td>\n",
       "      <td>Middle Super Output Areas and Intermediate Zones</td>\n",
       "      <td>MSOAIZ</td>\n",
       "      <td>6724</td>\n",
       "      <td>340</td>\n",
       "      <td>1180</td>\n",
       "      <td>785</td>\n",
       "      <td>871</td>\n",
       "      <td>526</td>\n",
       "      <td>1276</td>\n",
       "      <td>963</td>\n",
       "      <td>589</td>\n",
       "      <td>194</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     CDU  \\\n",
       "9937 E02000001        City of London 001   \n",
       "9938 E02000002  Barking and Dagenham 001   \n",
       "\n",
       "                                                         GeoCode GeoLabel  \\\n",
       "9937 E02000001  Middle Super Output Areas and Intermediate Zones   MSOAIZ   \n",
       "9938 E02000002  Middle Super Output Areas and Intermediate Zones   MSOAIZ   \n",
       "\n",
       "                GeoType  GeoType2  Total  Group1  Group2  Group3  Group4  \\\n",
       "9937 E02000001     7187      2730   2246     543     497     224     308   \n",
       "9938 E02000002     6724       340   1180     785     871     526    1276   \n",
       "\n",
       "                Group5  Group6  Group7  NC  \n",
       "9937 E02000001     212     178     249 NaN  \n",
       "9938 E02000002     963     589     194 NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = ['CDU','GeoCode','GeoLabel','GeoType','GeoType2','Total']\n",
    "for i in range(1,8):\n",
    "    colnames.append('Group' + str(i))\n",
    "colnames.append('NC')\n",
    "df = pd.read_csv('./Data/Data_NSSHRP_UNIT_URESPOP.csv', nrows=2, header=0, skiprows=[1], names=colnames)\n",
    "\n",
    "df.head() # Success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
