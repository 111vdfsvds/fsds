---
format:
  revealjs:
    theme: [serif, slides.scss]
author: "Jon Reades"
title: "Clustering"
footer: "Clustering • Jon Reades"
highlight-style: github
code-copy: true
code-line-numbers: true
slide-level: 2
title-slide-attributes:
  data-background-image: ../img/CASA_Logo_no_text.png
  data-background-size: cover
  data-background-position: center
  data-background-opacity: '0.17'
logo: ../img/CASA_logo.png
history: false
css: slides.css
---

## Spot the Difference

:::: {.columns}
::: {.column width="50%"}
### Classification

- Allocates *n* samples to *k* groups
- Works for different values of *k* 
- Different algorithms (*A*) present different views of group relationships
- Poor choices of *A* and *k* lead to weak understanding of data
- Typically works best in 1–2 dimensions

:::
::: {.column width="50%"}

### Clustering

- Allocates *n* samples to *k* groups
- Works for different values of *k*
- Different algorithms *A* present different views of group relationships
- Poor choices of *A* and *k* lead to weak understanding of data
- Typically works best in < 9 dimensions

:::
::::

::: {.notes}

Clustering algorithms can suffer from the 'curse of dimensionality' such that high-dimensional spaces cluster poorly without *either* dimensionality reduction *or* the use of specialist algorithms such as [Spherical *k*-Means](https://coclust.readthedocs.io/en/v0.2.1/api/clustering.html#module-coclust.clustering.spherical_kmeans).

:::

## The First Geodemographic Classification?

![](./img/Booth.png)

Source: [booth.lse.ac.uk/map/](https://booth.lse.ac.uk/map/)


## More than 100 Years Later

![](./img/Booth-Today.png)

Source: [vis.oobrien.com/booth/](http://vis.oobrien.com/booth/)


## Intimately Linked to Rise of The State

- Geodemographics only possible in context of a State -- without a Census it simply wouldn't work... until now?
- Clearly tied to social and economic 'control' and intervention: regeneration, poverty & exclusion, crime, etc.
- Presumes that *areas* are the relevant unit of analysis; in geodemographics these are usually called *neighbourhoods*... which should ring a few bells.
- In practice, we are in the realm of 'homophily', a.k.a. Tobler's *First Law of Geography*


## Where is it used?

Anything involving grouping individuals, households, or areas into larger 'groups'…

- Strategic marketing (above the line, targeted, etc.)
- Retail analysis (store location, demand modelling, etc.)
- Public sector planning (resource allocation, service development, etc.)

Could see it as a subset of *customer segmentation*.


# Computational Context

## Problem Domains

|                  | Continuous               | Categorical    |
| ---------------- | ------------------------ | -------------- |
| Supervised   | Regression               | Classification |
| Unsupervised | Dimensionality Reduction | Clustering     |


::: {.notes}

- In classification we 'know' the answer (we test against labels).
- In clustering we don't 'know' the answer (we look for clusters).

:::

# > What is a cluster?

::: {.notes}

A group of *similar* data points.

:::

# > What is the purpose of clustering?


::: {.notes}

To *generalise* from 'raw' data.

:::

## Measuring 'Fit'

> Usually working towards an 'objective criterion' for quality... these are known as cohesion and separation measures.


## How Your Data Looks...

Clustering is one area where standardisation (and, frequently, normalisation) are *essential*:

- You don't (normally) want scale in any one dimension to matter more than scale in another.
- You don't want differences between values in one dimension to matter more than differences in another.
- You don't want skew in one dimension to matter more than skew in another.

You also want *uncorrelated* variables... why?


## First Steps

You will normally want a *continuous* variable... so these types of data are especially problematic: 

- Dummies / One-Hot Encoded
- Categorical / Ordinal
- Possible solutions: *k*-modes, CCA, etc.

## Performance

Typically about trade-offs between:

:::: {.columns}
::: {.column width="25%"}
- Accuracy
- Generalisation
:::
::: {.column width="75%"}
![](img/Performance.png)
:::
::::

## Trade-Offs

Need to balance:

- Ability to cluster at *speed*.
- Ability to *replicate* results.
- Ability to cope with *fuzzy/indeterminate* boundaries.
- Ability to cope with *curse of dimensionality*.
- Underlying *representation* of group membership...


## Visualising the Trade-Offs

![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_comparison_001.png){width="80%"}

::: {.aside}
Details on [scikit-learn.org](https://scikit-learn.org/stable/modules/clustering.html).
:::

::: {.notes}

Notice the limitations to *k*-means: it may be fast but it's got problems if your data is non-linear/non-Gaussian.

And this doesn't even include options like HDBSCAN, HAC/Hierarchical Clustering, and many more!

:::

---

![](./img/ML_Learning.png){width="70%"}

::: {.aside}

[Interactive Demo](https://jeff3dx.github.io/mlearning/).

:::

## Putting it All into Context

![](https://scikit-learn.org/stable/_static/ml_map.png)


# Adding Geography

## Space Adds Complexity

We now have to consider *two more* types of clustering:

1. With respect to polygons: regions are built from adjacent zones that are more similar to one another than to other adjacent zones.
2. With respect to points: points are distributed in a way that indicates 'clumping' at particular scales.

::: {.notes}

Type 1 is probably what you were thinking of in terms of clustering.

Type 2 is point pattern analysis and should be considered a substantially different area of research and type of analysis.

:::

## Trade-offs (Again)...

Consider:

- Clustering algorithms are *inherently* spatial.
- Clustering algorithms do not take ~~space~~ *geography* into account.

Does this *matter*?

::: {.notes}

All clustering algorithms are about inter-observation and intra-cluster distances so they have *some* conceptualisation of 'space'.

Spatially-aware clustering algorithms exist but are generally much more computationally-intensive than 'regular ones'.

:::

## Different Approaches {.smaller}

| Algorithm | Pros | Cons  | Geographically Aware? |
|:----|:----------------|:----------------|:-------| 
| [k-Means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) | Fast. Deterministic. | Every observation to a cluster. | N. |
| [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) | Allows for clusters *and* outliers. | Slower. Choice of $\epsilon$ critical. Can end up with all outliers. | N, but implicit in $\epsilon$. |
| [OPTICS](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html) | Fewer parameters than DBSCAN. | Even slower. | N, but implicit in $\epsilon$. |
| [Hierarchical](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.htmlg)/ [HDBSCAN](https://hdbscan.readthedocs.io/en/latest/) | Can cut at any number of clusters. | No 'ideal' solution. | Y, with connectivity parameter. |
| [ADBSCAN](https://pysal.org/esda/generated/esda.adbscan.ADBSCAN.html) | Scales. Confidence levels. | May need large data set to be useful. Choice of $\epsilon$ critical. | Y. |
| [Max-p](https://splot.readthedocs.io/en/stable/users/tutorials/region.html#max-p) | Coherent regions returned. | Very slow if model poorly specified. | Y. |


## Setting the Relevant Distance

Many clustering algorithms rely on a distance specification (usually $\epsilon$). So to set this threshold:

- In high-dimensional spaces this threshold will need to be large.
- In high-dimensional spaces the scale will be meaningless (i.e. not have a real-world meaning, only an abstract one).
- In 2- or 3-dimensional (geographical) space this threshold *could* be meaningful (i.e. a value in metres *could* work).


## Choosing a Distance Metric

| *n* Dimensions | How to Set | Examples |
|:-------------|:---------------|:------------|
| 2 or 3 | Theory/Empirical Data | Walking speed; Commute distance |
| 2 or 3 | [K/L Measures](https://pysal.org/notebooks/explore/pointpats/distance_statistics.html#Interevent-Distance-Functions) | Plot with Simulation for CIs to identify significant 'knees'. |
| 3 | [Marked Point Pattern?](https://pysal.org/notebooks/explore/pointpats/marks.html#Marked-Point-Pattern) |
| > 3 | [kNN](https://towardsdatascience.com/machine-learning-clustering-dbscan-determine-the-optimal-value-for-epsilon-eps-python-example-3100091cfbc) | Calculate average kNN distance based on some expectation of connectivity. |

: {tbl-colwidths="[25,25,50]"}

::: {.notes}

Remember: inter-observation distance increases with dimensionality!

:::

# > There is *no* 'best' clustering algorithm, it's all about *judgement*.


# Geodemographics as a Business

## Experian

Specialist in consumer segmentation and geodemographics ([bit.ly/2jMRhAW](http://bit.ly/2jMRhAW)).

- Market cap: £14.3 *billion*.
- Mosaic: "synthesises of 850 million pieces of information… to create a segmentation that allocates 49 million individuals and 26 million households into one of 15 Groups and 66 detailed Types.""
- More than 450 variables used.

Most retail companies will have their own segmentation scheme. Competitors: CACI, Nielsen, etc.


## Experian Groups

![](./img/Experian.png)


## Experian Mapping

![](./img/Experian_Maps.png)


## Output Area Classification

OAC set up as 'open source' alternative to Mosaic:

- Well documented (UCL Geography a major contributor)
- Doesn't require a license or payment
- Can be tweaked/extended/reweighted by users as needed

# Thank you!