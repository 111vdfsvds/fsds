{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the AirBnB Data\n",
    "\n",
    "That should have given you a sense of some parallels/differences between Folium and Geopandas: Folium is more of a web-based, interactive visualisation library, while Geopandas is really built around large data sets and data analytics. We're now going to move into areas where Folium would have a lot of trouble keeping up: a data set scraped from the AirBnB web site. \n",
    "\n",
    "### Randomness & Reproducibility\n",
    "\n",
    "In fact, it turns out that rapid visualisation of the _full_ AirBnB data set using Geopandas/PySAL is hard: there's simply so much of it that visualisation is slow unless you're in a dedicated environment such as QGIS. So, for the _exploratory_ part of our work we'll want to work with a _sample_ -- but what happens if every time we take a sample we get a _different_ sample? That obviously makes things a bit harder, it would be handy if we could get the _same_ random sample every time _while_ we're doing our testing and development before expanding to the full data set.\n",
    "\n",
    "That's where `random.seed` comes in: by setting a seed we ensure that any process based on a random/random sampling process will be reproducible. In other words, we'll get the _same_ random sample each time. To under why this happens you'd need to read up on pseudo-randomness and computers but that's not really relevant here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "import random \n",
    "random.seed(123456789) # For reproducibility\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(os.path.join('data','airbnb','listings-summary.csv.gz'))\n",
    "\n",
    "print(\"Full data set shape is: \" + ' by '.join(str(i) for i in df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = df.sample(frac=0.1)\n",
    "print(\"Sample data set shape is: \" + ', '.join(str(i) for i in sample.shape))\n",
    "sample.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can _always_ do a 'quick and dirty' scatter plot to see if the data seems vaguely sensible -- it's obviously limited as a geo-visualisation but it can give you an _idea_ of whether or not you've done the right thing with your data. For example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#help(sns.jointplot)\n",
    "sns.jointplot(x=\"longitude\", y=\"latitude\", data=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that this 'map' isn't particularly good, but it does tell us that the longitude and latitude values are reasonable: you'd expect to find more AirBnB listings towards the middle of the city and there's a _hint_ of the Thames and the Lee Valley in there (though this is a bit of a stretch). To actually _map_ the data we'll need to be a little more rigorous... \n",
    "\n",
    "Let's step through what's going on below:\n",
    "1. We need to import the `Point` class so that we move from separate x and y columns to a single 'point' that Geopandas can work with.\n",
    "2. We then 'zip' up the x and y (i.e. lat and long) into pairs -- think of this as a simple way to pair _each_ x and y based on their row position and this allows us to move from separate columns to actual points.\n",
    "3. The next step is to tell Geopandas what projection our data is in -- raw lat and long are _usually_ recorded in WGS84 which has the EPSG identifier 4326 (_i.e._ epsg:4326).\n",
    "4. You'll notice that to create a new `GeoDataFrame` we do so _slightly_ differently from how we created a new `DataFrame` last term: we pass in the existing `pandas` data frame (`sample`), the CRS (projection), and finally the `geometry` that we created from the `zip` process.\n",
    "5. The last step is to reproject the geometry into OSGB (Ordnance Survey GB) which has the EPSG identifier 27700. \n",
    "\n",
    "You can see the results of this step in the final step where we print out the first 3 rows of the reprojected data: notice that the point coordinates are no longer in lat/long!\n",
    "\n",
    "Some of this _might_ seem a little tedious, but it's incredibly useful to be able to automate this process: we can reproject a whole series of shapefiles (e.g. every single file in a directory!), we can convert CSV files into shapes that load automatically into QGIS instead of having to do this process manually..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "# Convert x,y to Points using zip(...)\n",
    "geometry = [Point(xy) for xy in zip(sample.longitude, sample.latitude)]\n",
    "\n",
    "print(\"From the data frame...\")\n",
    "print(sample.head(3)[['longitude','latitude']])\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\" \")\n",
    "print(\"From the geometry zip...\")\n",
    "print([\", \".join([str(p.x), str(p.y)]) for p in geometry[0:3]])\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\" \")\n",
    "# Initialise to WGS84\n",
    "crs = {'init' :'epsg:4326'}\n",
    "sdf = gpd.GeoDataFrame(sample, crs=crs, geometry=geometry)\n",
    "\n",
    "# Reproject into OSGB\n",
    "sdf = sdf.to_crs({'init' :'epsg:27700'})\n",
    "print(sdf.head(3)[['neighbourhood','geometry']])\n",
    "\n",
    "# And save it as a new shapefile\n",
    "sdf.to_file(os.path.join('shapes','AirBnB-Sample.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the AirBnB sample will take some time... so be patient! You'll notice that the results are now also reported in OSGB units, not lat/long, so this is one way in which GeoPandas is more 'knowledgeable' about geodata than pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving to a Shapefile!\n",
    "\n",
    "_Aaaaaand_ as a final step: let's save our data sample as a brand new shape file that we can open directly in QGIS or ArcGIS. This is going to be rather useful: you could create your entire workflow in an automated, replicable fashion, and then just write the results out to a Shapefile so that you can get your visualisation _just right_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sdf.to_file(os.path.join('data','airbnb','listings-summary.shp'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [gsa2017]",
   "language": "python",
   "name": "Python [gsa2017]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
