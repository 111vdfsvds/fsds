{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Week’s Overview\n",
    "\n",
    "This week we're going to apply a number of the concepts covered in class in order to read a remote CSV file, turn it into data, and then perform some simple analyses on it. We're going to first do it 'by hand' (building the tools we need) and then using the 'pandas' package that gives us a very different way to do things.\n",
    "\n",
    "## Learning Outcomes\n",
    "\n",
    "By the end of this practical you should:\n",
    "- Have read a remote data file\n",
    "- Written a function to derive some statistics\n",
    "- Have imported a package\n",
    "- Have made use of methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking a Second to Think\n",
    "\n",
    "To a computer, reading data from a remote location (e.g. a web site halfway around the world) is not really any different from reading one that's sitting on your desktop, you just need to make set it up a bit differently and, in Python, make use of a different _package_. In all cases – local and remote – Python gives you a 'filehandle' that supports certain operations like 'open a filehandle', 'read a line', 'close a filehandle'. It's called a filehandle because it's something that gives you a 'grip' on a file-like object.\n",
    "\n",
    "I also want you to understand how we're approach the problem set out above: we want to read a remote file (i.e. a text file halfway round the planet), turn it into a local data structure (i.e a list or a dictionary), and then perform operations on it using functions (e.g. calculate the mean, find the easternmost city, etc.).\n",
    "\n",
    "_**But**_, we _don't_ try to do all of this at once by writing a whole lot of code and the hoping for the best; when you're tackling a problem like this you break it down into separate, simpler steps, and then tick them off one by one. So first we'll get Python _reading_ remote data, then we'll _convert_ text into data, and finally we'll _analyse_ the data using functions.\n",
    "\n",
    "_**Note**_: you might also find it helpful to take a close look at the URL that we are reading by pasting this link into a web browser: http://www.reades.com/CitiesWithWikipediaData-simple.csv. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Reading a Remote File\n",
    "\n",
    "So, as I said, we are going to parse a data file hosted on a remote web site. This is just the first step: we are going to build from this first step towards more substantial exercises and, eventually, you could easily request Megabytes of data in real-time according to flexibly-specified parameters!\n",
    "\n",
    "You'll probably need to do a quick Google in order to make sense of what you're about to do; I'd suggest \"`read remote CSV file Python urllib2`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function urlopen in module urllib2:\n",
      "\n",
      "urlopen(url, data=None, timeout=<object object>, cafile=None, capath=None, cadefault=False, context=None)\n",
      "\n",
      "URL: http://www.reades.com/CitiesWithWikipediaData-simple.csv.\n",
      "\n",
      "id,Name,Rank,Longitude,Latitude,Population\n",
      "1,Greater London,1,-18162.92767,6711153.709,9787426\n",
      "2,Greater Manchester,2,-251761.802,7073067.458,2553379\n",
      "3,West Midlands,3,-210635.2396,6878950.083,2440986\n",
      "4,West Yorkshire,4,-185959.3022,7145450.207,1777934\n",
      "5,Glasgow,5,-473845.2389,7538620.144,1209143\n",
      "6,Liverpool,6,-340595.1768,7063197.083,864122\n",
      "7,South Hampshire,7,-174443.8647,6589419.084,855569\n",
      "8,Tyneside,8,-187604.3647,7356018.207,774891\n",
      "9,Nottingham,9,-131672.2399,6979298.895,729977\n",
      "10,Sheffield,10,-163545.3257,7055177.403,685368\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "\n",
    "help(urllib2.urlopen)\n",
    "\n",
    "url = \"http://www.reades.com/CitiesWithWikipediaData-simple.csv\"\n",
    "print(\"URL: \" + url + \".\\n\")\n",
    "\n",
    "response = urllib2.urlopen(url) # ???\n",
    "for line in response: # ???\n",
    "    print line.rstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've managed to get the code above to run and have received 11 rows of text in response to your `urlopen` query then, congratulations, You've now read a text file sitting on a server in, I think, Alberta, Canada and Python _didn't care_. \n",
    "\n",
    "The last row should be `10,Sheffield,10,-163545.3257,7055177.403,685368`.\n",
    "\n",
    "### URLLIB2\n",
    "\n",
    "In this particular case, I 'gave' you the fact that you'd need to make use of the `urllib2` package in order to read the file. But you could almost certainly have Googled this for yourself using something like 'Python read file on server'...\n",
    "\n",
    "Urllib2 is a very useful library, but compared to pandas (which we'll see later), it's pretty simple since it just sends a 'request' to a web site and 'reads' the results. You can also do things like submit a form (e.g. you could submit hundreds of applications for a free TV if someone ran a competition... that's why they have 'captchas' now).\n",
    "\n",
    "Anyway, that's some background, let's move on to step 2! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Turning Text into Data\n",
    "\n",
    "We now need to work on turning that text into useful data. You'll notice that we are dealing with a _CSV_ (Comma-Separated Value) file and that the format is quite simple since none of the rows have fields that contain commas. So to turn this into data we just need to _split_ the row on commas.\n",
    "\n",
    "In the code below, `dir('string')` lists the available methods for strings. Methods that start and end with `__` are generally considered private, so you can skip over these and focus on the ones further down that are designed to be useful to programmers. Can you spot the method that is most likely to be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__getslice__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_formatter_field_name_split',\n",
       " '_formatter_parser',\n",
       " 'capitalize',\n",
       " 'center',\n",
       " 'count',\n",
       " 'decode',\n",
       " 'encode',\n",
       " 'endswith',\n",
       " 'expandtabs',\n",
       " 'find',\n",
       " 'format',\n",
       " 'index',\n",
       " 'isalnum',\n",
       " 'isalpha',\n",
       " 'isdigit',\n",
       " 'islower',\n",
       " 'isspace',\n",
       " 'istitle',\n",
       " 'isupper',\n",
       " 'join',\n",
       " 'ljust',\n",
       " 'lower',\n",
       " 'lstrip',\n",
       " 'partition',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'rjust',\n",
       " 'rpartition',\n",
       " 'rsplit',\n",
       " 'rstrip',\n",
       " 'split',\n",
       " 'splitlines',\n",
       " 'startswith',\n",
       " 'strip',\n",
       " 'swapcase',\n",
       " 'title',\n",
       " 'translate',\n",
       " 'upper',\n",
       " 'zfill']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've found the method, why not use the `help` function to figure out how to make use of it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function split:\n",
      "\n",
      "split(...)\n",
      "    S.split([sep [,maxsplit]]) -> list of strings\n",
      "    \n",
      "    Return a list of the words in the string S, using sep as the\n",
      "    delimiter string.  If maxsplit is given, at most maxsplit\n",
      "    splits are done. If sep is not specified or is None, any\n",
      "    whitespace string is a separator and empty strings are removed\n",
      "    from the result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help('string'.split) #???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so you've tracked down the way to split a string using a delimiter. Let's test it using our sample string to make sure it works the way we think it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', 'Sheffield', '10', '-163545.3257', '7055177.403', '685368']\n"
     ]
    }
   ],
   "source": [
    "test = \"10,Sheffield,10,-163545.3257,7055177.403,685368\".split(\",\") #???\n",
    "print test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now that you've figured out how to make use of the appropriate method using `help` and a simple test, it's time to revise the code above so that it turns the remote file into data. You can hopefully see how we're breaking a complex problem down into a set of _increments_, each of which is a bit easier to write and understand. \n",
    "\n",
    "Now, remember that ultimately we want to make use of the data in this file, so simply printing it back out ins't particularly helpful. What we really want to do is stash the data we've read in some kind of _data structure_ that resembles the CSV file but is easier and faster for the computer to navigate.\n",
    "\n",
    "We need:\n",
    "1. To keep the rows in order\n",
    "2. To keep the columns in order\n",
    "\n",
    "With what we've covered in previous sessions and what we've covered in class, what approach might allow us to do this? _Hint:_ is it likely to be a dictionary? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'Name', 'Rank', 'Longitude', 'Latitude', 'Population'], ['1', 'Greater London', '1', '-18162.92767', '6711153.709', '9787426'], ['2', 'Greater Manchester', '2', '-251761.802', '7073067.458', '2553379'], ['3', 'West Midlands', '3', '-210635.2396', '6878950.083', '2440986'], ['4', 'West Yorkshire', '4', '-185959.3022', '7145450.207', '1777934'], ['5', 'Glasgow', '5', '-473845.2389', '7538620.144', '1209143'], ['6', 'Liverpool', '6', '-340595.1768', '7063197.083', '864122'], ['7', 'South Hampshire', '7', '-174443.8647', '6589419.084', '855569'], ['8', 'Tyneside', '8', '-187604.3647', '7356018.207', '774891'], ['9', 'Nottingham', '9', '-131672.2399', '6979298.895', '729977'], ['10', 'Sheffield', '10', '-163545.3257', '7055177.403', '685368']]\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "\n",
    "url = \"http://www.reades.com/CitiesWithWikipediaData-simple.csv\"\n",
    "\n",
    "cityData = [] # Somewhere to store the data\n",
    "\n",
    "response = urllib2.urlopen(url) \n",
    "for line in response: \n",
    "    cityData.append( line.rstrip().split(\",\") ) # ???\n",
    "\n",
    "print cityData # Check it worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "Everything we do form here on out will be modelled on the code that we've just finished, so if you get lost you can always come back to this step and start over! Sometimes, you can tie yourself in knots thinking about a problem and it ends up being easier to throw everything out and start again with a simpler approach or new angle...\n",
    "\n",
    "We can write functions in much the same way that we developed the code above: incrementally. Rather than just sitting down, typing out your function, and hoping for the best, it's often easier to write the code first and _then_ turn it into a function! Let's try this for the code we've written so far by creating a function that will access _any_ URL and return a 'simple' list-of-lists that represents any CSV data stored at the URL's location. \n",
    "\n",
    "### Designing a function\n",
    "\n",
    "The first stage in writing a function is to figure out what inputs and outputs it should have. For this function that is fairly straightforward:\n",
    "* We give the function a URL that we want to it read in\n",
    "* The function gives us back a list-of-lists containing the CSV data\n",
    "\n",
    "We should also give it a name that is fairly obvious to anyone else who comes along and tries to read our code; how about: `readRemoteCSV`?\n",
    "\n",
    "### Creating  a function\n",
    "\n",
    "This is a good point to hit Google or StackOverflow for some help. We're trying to `write a function in Python` so why not search for that? I quickly found some useful ones from sites like TutorialPoint and the Python documentation.\n",
    "\n",
    "I've created the sketch of a function below but have left out quite a bit that you'll have to fill in by searching on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL 1:\n",
      "\n",
      "[['id', 'Name', 'Rank', 'Longitude', 'Latitude', 'Population'], ['1', 'Greater London', '1', '-18162.92767', '6711153.709', '9787426'], ['2', 'Greater Manchester', '2', '-251761.802', '7073067.458', '2553379'], ['3', 'West Midlands', '3', '-210635.2396', '6878950.083', '2440986'], ['4', 'West Yorkshire', '4', '-185959.3022', '7145450.207', '1777934'], ['5', 'Glasgow', '5', '-473845.2389', '7538620.144', '1209143'], ['6', 'Liverpool', '6', '-340595.1768', '7063197.083', '864122'], ['7', 'South Hampshire', '7', '-174443.8647', '6589419.084', '855569'], ['8', 'Tyneside', '8', '-187604.3647', '7356018.207', '774891'], ['9', 'Nottingham', '9', '-131672.2399', '6979298.895', '729977'], ['10', 'Sheffield', '10', '-163545.3257', '7055177.403', '685368']]\n",
      "URL 2:\n",
      "\n",
      "[['id', 'Name', 'Rank', 'Longitude', 'Latitude', 'Population', 'Area', 'Density', 'Subs', 'MetroArea', 'Changes'], ['1', 'Greater London', '1', '-18162.92767', '6711153.709', '9787426', '1737.9', '5630', '\"London Boroughs', ' Hemel Hempstead', ' Watford', ' Woking', ' Harlow', ' St Albans', ' Bracknell\"', 'London', '\"The addition of Guildford', ' Harlow', ' Bracknell and St Albans\"'], ['2', 'Greater Manchester', '2', '-251761.802', '7073067.458', '2553379', '630.3', '4051', '\"Manchester', ' Salford', ' Bolton', ' Stockport', ' Oldham', ' Rochdale', ' Bury', ' Trafford', ' Tameside\"', 'Manchester', '\"The addition of Golborne', ' Glossop and Newton-le-Willows\"'], ['3', 'West Midlands', '3', '-210635.2396', '6878950.083', '2440986', '598.9', '4076', '\"Birmingham', ' Wolverhampton', ' West Bromwich', ' Dudley', ' Walsall', ' Solihull\"', 'Birmingham', ''], ['4', 'West Yorkshire', '4', '-185959.3022', '7145450.207', '1777934', '487.8', '3645', '\"Leeds', ' Bradford', ' Wakefield', ' Huddersfield', ' Dewsbury', ' Keighley', ' Halifax\"', 'Leeds-Bradford', 'The addition of Halifax'], ['5', 'Glasgow', '5', '-473845.2389', '7538620.144', '1209143', '368.5', '3390', '\"Glasgow', ' Paisley', ' Clydebank\"', 'Glasgow', ''], ['6', 'Liverpool', '6', '-340595.1768', '7063197.083', '864122', '199.6', '4329', '\"Liverpool', ' Bootle', ' Litherland', ' Crosby', ' Prescot', ' St. Helens', ' Ashton-in-Makerfield\"', 'Liverpool', 'The addition of Ashton-in-Makerfield'], ['7', 'South Hampshire', '7', '-174443.8647', '6589419.084', '855569', '192', '4455', '\"Southampton', ' Portsmouth', ' Eastleigh', ' Gosport', ' Fareham', ' Havant', ' Horndean\"', 'Southampton-Portsmouth', 'Portsmouth Urban Area and Southampton Urban Area combined into one.'], ['8', 'Tyneside', '8', '-187604.3647', '7356018.207', '774891', '180.5', '4292', '\"Newcastle upon Tyne', ' Gateshead', ' South Shields', ' Tynemouth', ' Wallsend', ' Whitley Bay', ' Jarrow\"', 'Newcastle-Sunderland', '\"Washington', ' Chester-Le-Street', ' Hetton-le-Hole and Houghton-le-Spring are no longer part of the built-up area.\"'], ['9', 'Nottingham', '9', '-131672.2399', '6979298.895', '729977', '176.4', '4139', '\"Nottingham', ' Beeston', ' Carlton', ' West Bridgford', ' Ilkeston', ' Hucknall\"', 'Nottingham-Derby', ''], ['10', 'Sheffield', '10', '-163545.3257', '7055177.403', '685368', '167.5', '4092', '\"Sheffield', ' Rotherham', ' Rawmarsh\"', 'Sheffield', ''], ['11', 'Bristol', '11', '-283223.6223', '6708480.482', '617280', '144.4', '4274', '\"Bristol', ' Filton', ' Pill', ' Frampton Cotterell', ' Kingswood', ' Warmley', ' Mangotsfield', ' Winterbourne\"', 'Bristol', ''], ['12', 'Belfast', '12', '-659942.9337', '7289187.543', '579127', '', '', '', 'Belfast', ''], ['13', 'Leicester', '13', '-128587.7477', '6917403.419', '508916', '109.4', '4653', '\"Leicester', ' Syston', ' Whetstone', ' Birstall', ' Narborough', ' Enderby\"', 'Leicester', 'Ratby no longer part of the built-up area.'], ['14', 'Edinburgh', '14', '-353961.3096', '7552397.542', '482005', '', '', '', 'Edinburgh', ''], ['15', 'Brighton and Hove', '15', '-18368.56048', '6593326.107', '474485', '89.4', '5304', '\"Brighton and Hove', ' Worthing', ' Littlehampton', ' Shoreham-by-Sea\"', 'Brighton', '\"Rottingdean', ' Saltdean and Findon are no longer part of the built-up area.\"'], ['16', 'Bournemouth/Poole', '16', '-243742.1224', '6565360.045', '466266', '131', '3559', '\"Bournemouth', ' Poole', ' Christchurch', ' Ferndown', ' New Milton', ' Wimborne Minster\"', 'Bournemouth/Poole', 'Ferndown and Wimborne Minster now part of the built-up area.'], ['17', 'Cardiff', '17', '-357251.4345', '6710125.544', '447287', '102.3', '4370', '\"Cardiff', ' Caerphilly', ' Penarth', ' Pontypridd\"', 'Cardiff-Newport', 'Caerphilly and Pontypridd now part of the built-up area.'], ['18', 'Teesside', '18', '-136813.0602', '7284252.355', '376633', '108.2', '3482', '\"Middlesbrough', ' Stockton-On-Tees', ' Billingham', ' Redcar\"', 'Middlesbrough', '\"Eston & Southbank now part of Middlesbrough sub-division', ' no longer counted as separate sub-division\"'], ['19', 'Stoke-on-Trent', '19', '-246620.9817', '6990197.434', '372775', '103.9', '3588', '\"Stoke-on-Trent', ' Newcastle-under-Lyme', ' Kidsgrove\"', 'Stoke-on-Trent', ''], ['20', 'Coventry', '20', '-169303.0444', '6876688.122', '359262', '81.3', '4420', '\"Coventry', ' Bedworth\"', 'Birmingham', ''], ['21', 'Sunderland', '21', '-156142.5445', '7336483.09', '335415', '83.5', '4018', '\"Sunderland', ' Washington', ' Chester-Le-Street', ' Hetton-le-Hole', ' Houghton-le-Spring\"', 'Newcastle-Sunderland', '\"Addition of Washington', ' Chester-Le-Street', ' Hetton-le-Hole and Houghton-le-Spring\"'], ['22', 'Birkenhead', '22', '-373290.7939', '7038726.778', '325264', '88.2', '3687', '\"Birkenhead', ' Wallasey', ' Ellesmere Port', ' Bebington\"', 'Liverpool', ''], ['23', 'Reading', '23', '-113370.9196', '6703134.029', '318014', '83.7', '3800', '\"Reading', ' Wokingham', ' Woodley', ' Crowthorne\"', 'London', 'Bracknell no longer part of the built-up area.'], ['24', 'Kingston upon Hull', '24', '-41707.88464', '7124167.211', '314018', '82.6', '3802', '\"Kingston upon Hull', ' Cottingham', ' Hessle\"', 'Hull', ''], ['25', 'Preston', '25', '-306768.5792', '7125401.008', '313322', '82.4', '3802', '\"Preston', ' Bamber Bridge', ' Chorley', ' Fulwood', ' Leyland\"', 'Preston', 'The addition of Longton and Adlington to the built-up area.'], ['26', 'Newport', '26', '-283737.7043', '6751971.822', '306844', '84.2', '3643', '\"Newport', ' Pontypool', ' Cwmbran', ' Blackwood', ' Risca', ' Ystrad Mynach\"', 'Cardiff-Newport', '\"Pontypool', ' Cwmbran and Blackwood added to the built-up area.\"'], ['27', 'Swansea', '27', '-451534.0788', '6738811.322', '300352', '87.6', '3431', '\"Swansea', ' Neath', ' Port Talbot', ' Ystradgynlais', ' Pontardawe\"', 'Swansea/Neath/Port Talbot', 'Ystradgynlais now part of the built-up area.'], ['28', 'Southend-on-Sea', '28', '78176.04472', '6724005.759', '295310', '71.8', '4111', '\"Southend-on-Sea', ' Hullbridge', ' Rayleigh', ' Rochford\"', 'London', 'Hullbridge now part of the built-up area.'], ['29', 'Derby', '29', '-168172.064', '6970353.868', '270468', '64.1', '4219', '\"Derby', ' Borrowash', ' Duffield\"', 'Nottingham-Derby', ''], ['30', 'Plymouth', '30', '-464283.3132', '6512203.963', '260203', '59.7', '4356', '\"Plymouth', ' Plymstock\"', 'Plymouth', ''], ['31', 'Luton', '31', '-53017.6893', '6785284.337', '258018', '50.7', '5088', '\"Luton', ' Dunstable', ' Houghton Regis\"', 'London', ''], ['32', 'Farnborough/Aldershot', '32', '-87152.73608', '6664783.509', '252397', '78.5', '3217', '\"Farnborough', ' Aldershot', ' Camberley', ' Farnham', ' Frimley', ' Sandhurst', ' Yateley\"', 'London', ''], ['33', 'Medway Towns', '33', '58435.29477', '6698507.291', '243931', '52.2', '4677', '\"Gillingham', ' Chatham', ' Rochester\"', 'London', ''], ['34', 'Blackpool', '34', '-342137.4229', '7142674.164', '239409', '61.3', '3908', '\"Blackpool', ' Lytham St Annes', ' Poulton-le-Fylde', ' Thornton', ' Cleveleys\"', 'Blackpool', 'Fleetwood no longer forms part of the built-up area.'], ['35', 'Milton Keynes', '35', '-88797.79857', '6803791.29', '229941', '62.5', '3678', '\"\\'Milton Keynes\\'', '[7] Bletchley', ' Newport Pagnell', ' Woburn Sands\"', 'Milton Keynes', 'The addition of Woburn Sands.'], ['36', 'Northampton', '37', '-108538.5485', '6849853.04', '215963', '57.9', '3731', '\"Northampton', ' Collingtree\"', 'Northampton', ''], ['37', 'Barnsley/Dearne Valley', '36', '-167966.4312', '7087358.938', '223281', '59.7', '3739', '\"Barnsley', ' Wath upon Dearne', ' Wombwell', ' Hoyland\"', 'Sheffield', ''], ['38', 'Norwich', '38', '142539.1149', '6915861.173', '213166', '61.9', '3444', '\"Norwich', ' Taverham', ' Costessey', ' Cringleford', ' Hellesdon\"', 'Norwich', ''], ['39', 'Aberdeen', '39', '-237470.3216', '7791034.42', '207932', '', '', '', 'Aberdeen', ''], ['40', 'Swindon', '40', '-197166.2905', '6721743.798', '185609', '47.1', '3945', '\"Swindon', ' Haydon Wick', ' Stratton St. Margaret', ' Broad Blunsdon', ' Blunsdon St Andrew', ' Wroughton\"', 'Swindon', ''], ['41', 'Crawley', '41', '-21144.60345', '6652651.174', '180508', '58.1', '3107', '\"Crawley', ' Horley', ' East Grinstead', ' Copthorne', ' Crawley Down\"', 'London', '\"The addition of East Grinstead', ' Copthorne and Crawley Down.\"'], ['42', 'Ipswich', '42', '125265.9587', '6817157.423', '178835', '49.1', '3639', '\"Ipswich', ' Kesgrave', ' Woodbridge\"', 'Ipswich', 'The addition of Woodbridge.'], ['43', 'Wigan', '43', '-298337.6339', '7086947.672', '175405', '43.8', '4009', '\"Wigan', ' Skelmersdale', ' Standish', ' Ince-in-Makerfield\"', 'Manchester', ''], ['44', 'Mansfield', '44', '-136298.9781', '7011274.798', '171958', '48.4', '3556', '\"Mansfield', ' Sutton-in-Ashfield', ' Kirkby-in-Ashfield', ' Mansfield Woodhouse\"', 'Nottingham-Derby', ''], ['45', 'Oxford', '45', '-140411.6344', '6760402.767', '171380', '37.4', '4585', '\"Oxford', ' Kennington', ' Wheatley\"', 'Oxford', 'The addition of Kennington and Wheatley.'], ['46', 'Warrington', '46', '-299160.1652', '7058981.61', '165456', '44.9', '3686', 'Warrington', 'Liverpool', ''], ['47', 'Slough', '47', '-72141.54081', '6715986.08', '163777', '34.1', '4797', '\"Slough', ' Stoke Poges', ' Poyle\"', 'London', ''], ['48', 'Peterborough', '48', '-30192.44717', '6905990.798', '163379', '44.2', '3693', '\"Peterborough', ' Farcet\"', 'Peterborough', ''], ['49', 'Cambridge', '49', '10934.11522', '6840188.298', '158434', '42.1', '3760', '\"Cambridge', ' Fen Ditton', ' Girton', ' Histon\"', 'Cambridge', 'Addition of Histon and Impington and Fen Ditton'], ['50', 'Doncaster', '50', '-129718.7281', '7086125.141', '158141', '43.5', '3634', '\"Doncaster', ' Bentley', ' Armthorpe', ' Sprotbrough\"', 'Sheffield', 'Addition of Bessacarr'], ['51', 'Dundee', '51', '-340286.7276', '7653671.702', '157444', '', '', '', 'Dundee', ''], ['52', 'York', '52', '-123961.0094', '7163443.078', '153717', '34', '4518', '\"York', ' Earswick\"', 'York', ''], ['53', 'Gloucester', '53', '-252275.8841', '6775208.329', '150053', '40.4', '3718', '\"Gloucester', ' Innsworth\"', 'Gloucester-Cheltenham', ''], ['54', 'Burnley', '54', '-250425.1888', '7130181.971', '149422', '35.7', '4183', '\"Burnley', ' Padiham', ' Brierfield Colne', ' Barrowford Nelson\"', 'Blackburn-Burnley', ''], ['55', 'Basildon', '57', '43629.73231', '6724057.167', '144859', '37.1', '3902', '\"Basildon', ' Wickford', ' Ramsden Heath', ' North Benfleet\"', 'London', 'The addition of Wickford to the urban area.'], ['56', 'Grimsby', '58', '-11891.12691', '7088438.51', '134160', '35.3', '3804', '\"Grimsby', ' Cleethorpes', ' Waltham\"', 'Grimsby', 'New Waltham is no longer part of the Built-up area.'], ['57', 'Hastings', '59', '62856.40023', '6599340.867', '133422', '33.2', '4019', '\"Hastings', ' Bexhill\"', 'Hastings', ''], ['58', 'High Wycombe', '60', '-87666.81811', '6735058.523', '133204', '39.2', '3398', '\"High Wycombe', ' Cookham', ' Hughenden Valley\"', 'London', ''], ['59', 'Thanet', '61', '140174.3375', '6678303.867', '125370', '27.9', '4495', '\"Margate', ' Ramsgate', ' Broadstairs\"', 'Thanet', ''], ['60', 'Accrington/Rossendale', '62', '-274381.4113', '7122059.475', '125059', '30', '4168', '\"Accrington', ' Rawtenstall', ' Bacup', ' Great Harwood', ' Haslingden', ' Oswaldtwistle\"', 'Blackburn-Burnley', 'Accrington Urban Area and Rossendale Urban Area combined.'], ['61', 'Burton-upon-Trent', '63', '-183491.7085', '6946860.319', '122199', '35', '3487', '\"Burton-upon-Trent', ' Swadlincote\"', 'Burton-upon-Trent', '\"The addition of Swadlincote', ' Stapenhill and Winshill[8]\"'], ['62', 'Colchester', '64', '99459.04075', '6777830.148', '121859', '32.7', '3732', '\"Colchester', ' Marks Tey\"', 'Colchester', ''], ['63', 'Eastbourne', '65', '30777.68157', '6580833.914', '118219', '25.1', '4705', '\"Eastbourne', ' Polegate\"', 'Brighton', ''], ['64', 'Exeter', '66', '-391592.1141', '6566850.883', '117763', '28.5', '4133', '\"Exeter', ' Topsham\"', 'Exeter', ''], ['65', 'Cheltenham', '67', '-228319.6615', '6781531.538', '116447', '28.9', '4034', '\"Cheltenham', '\"', 'Gloucester-Cheltenham', ''], ['66', 'Paignton/Torquay', '68', '-398172.3641', '6525724.32', '115410', '31.5', '3667', '\"Paignton', ' Torquay', ' Marldon\"', 'Torbay', ''], ['67', 'Lincoln', '69', '-62219.75763', '7025463.462', '114879', '32.7', '3518', '\"Lincoln', ' North Hykeham\"', 'Lincoln', ''], ['68', 'Chesterfield', '70', '-159278.4449', '7029576.118', '113057', '34.6', '3263', '\"Chesterfield', ' Staveley', ' Wingerworth', ' Holymoorside\"', 'Sheffield', 'Addition of Wingerworth to the Built-up area.'], ['69', 'Chelmsford', '71', '51289.55456', '6754850.681', '111511', '26.2', '4259', '\"Chelmsford', ' Little Waltham\"', 'London', ''], ['70', 'Basingstoke', '72', '-125554.6637', '6669307.431', '107642', '29.4', '3662', 'Basingstoke', 'London', ''], ['71', 'Maidstone', '73', '56224.74204', '6670129.963', '107627', '25.4', '4229', 'Maidstone', 'London', ''], ['72', 'Bedford', '74', '-53171.9139', '6826410.9', '106940', '24.8', '4309', '\"Bedford', ' Kempston\"', 'Bedford', '', 'Worcester', '75', '-248934.3509', '6837103.806', '101659', '24.7', '4121', '\"Worcester', ' Norton\"', 'Worcester', '']]\n"
     ]
    }
   ],
   "source": [
    "def readRemoteCSV(url):\n",
    "    \"\"\"\n",
    "    Reads a remote CSV file and returns\n",
    "    a list-of-lists containing the data.\n",
    "    \"\"\"\n",
    "    urlData = [] # Somewhere to store the data\n",
    "\n",
    "    response = urllib2.urlopen(url) # ???\n",
    "    for line in response: \n",
    "        urlData.append( line.rstrip().split(\",\") ) # ???\n",
    "        \n",
    "    return urlData # ???\n",
    "\n",
    "print \"URL 1:\\n\"\n",
    "data1 = readRemoteCSV(\"http://www.reades.com/CitiesWithWikipediaData-simple.csv\")\n",
    "print data1\n",
    "\n",
    "# Now...\n",
    "\n",
    "print \"URL 2:\\n\"\n",
    "data2 = readRemoteCSV(\"http://www.reades.com/CitiesWithWikipediaData.csv\")\n",
    "print data2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review!\n",
    "\n",
    "OK, let's just take a look at that again: do you see how, by packaging up the code as a function, we have made it more useful and more re-usable? We now have a little snippet of code that we can _call_ to process _any_ valid URL. So we called `readRemoteCSV` once to read the 'Cities-simple.csv' file, and again to read to the much larger 'Cities.csv' file. We could read 1,000 other URLs using the same function! Now our code is a lot cleaner because we don't need to keep reading lines of code about calling remote files and parsing them; and it's also a lot easier to maintain because if we want to _change_ the way that we parse remote CSV files then we only need to do it in _one place_ and then everywhere that we use this function benefits form the improvement... which is what we're going to do now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Mean\n",
    "\n",
    "I'd like you to write a function that will enable you to calculate the mean city size of data retrieved from _any_ URL. So you should be able to call _one_ function that will work for both `Cities.csv` and `Cities-simple.csv`. You'll need to look closely at how the two files are 'laid out': where is the population column, and how would be iterate over the rows to find the mean?\n",
    "\n",
    "### Designing the Function\n",
    "\n",
    "OK, we know that `readRemoteCSV` will give us back a list-of-lists: the 'big list' contains a large number of 'small lists', each of which represents a row in the data set. Let's break this down:\n",
    "* We know that we will have a LoL (List-of-Lists) to work from\n",
    "* We know that each 'small list' represents a row in the data\n",
    "* We know that the position of the column of interest might change from data set to data set\n",
    "* We know that we'll need to convert every value to a... `float`? `int`? Let's assume `float`.\n",
    "* We know that we'll need to sum up the values\n",
    "* We know that we'll need to keep track of how many rows of data there are\n",
    "\n",
    "As before, let's start by working it out _as code_, and then package it up _as a function_ once it's working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'Name', 'Rank', 'Longitude', 'Latitude', 'Population']\n",
      "['1', 'Greater London', '1', '-18162.92767', '6711153.709', '9787426']\n",
      "['2', 'Greater Manchester', '2', '-251761.802', '7073067.458', '2553379']\n",
      "['3', 'West Midlands', '3', '-210635.2396', '6878950.083', '2440986']\n",
      "['4', 'West Yorkshire', '4', '-185959.3022', '7145450.207', '1777934']\n",
      "['5', 'Glasgow', '5', '-473845.2389', '7538620.144', '1209143']\n",
      "['6', 'Liverpool', '6', '-340595.1768', '7063197.083', '864122']\n",
      "['7', 'South Hampshire', '7', '-174443.8647', '6589419.084', '855569']\n",
      "['8', 'Tyneside', '8', '-187604.3647', '7356018.207', '774891']\n",
      "['9', 'Nottingham', '9', '-131672.2399', '6979298.895', '729977']\n",
      "['10', 'Sheffield', '10', '-163545.3257', '7055177.403', '685368']\n"
     ]
    }
   ],
   "source": [
    "# The starting point...\n",
    "for row in data1:\n",
    "    print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitude\n",
      "-18162.92767\n",
      "-251761.802\n",
      "-210635.2396\n",
      "-185959.3022\n",
      "-473845.2389\n",
      "-340595.1768\n",
      "-174443.8647\n",
      "-187604.3647\n",
      "-131672.2399\n",
      "-163545.3257\n"
     ]
    }
   ],
   "source": [
    "# Now let's track a particular column\n",
    "col = 3\n",
    "for row in data1:\n",
    "    print row[col] # ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e3af391651b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "# And now let's figure out the mean\n",
    "col   = 3\n",
    "total = 0 # What's the sum of the values?\n",
    "count = 0 # How many values have we read?\n",
    "for row in data1:\n",
    "    print row[col]\n",
    "    value = row[col]\n",
    "    count += 1\n",
    "    total += value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooops, that last one didn't work so well. How would you fix this?\n",
    "\n",
    "Here are _two_ hints:\n",
    "1. What is the count when you are reading the first row (which contains the column name)?\n",
    "2. If the value is a string, how do you convert it to an int\n",
    "\n",
    "_P.S._ I also broke one very important thing deliberately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population\n",
      "9787426\n",
      "2553379\n",
      "2440986\n",
      "1777934\n",
      "1209143\n",
      "864122\n",
      "855569\n",
      "774891\n",
      "729977\n",
      "685368\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# And now let's figure out the mean\n",
    "col   = 5\n",
    "total = 0.0 # What's the sum of the values?\n",
    "count = 0   # How many values have we read?\n",
    "for row in data1:\n",
    "    print(row[col])\n",
    "    if count == 0: # ???\n",
    "        count += 1\n",
    "    else: \n",
    "        value = float(row[col]) # ???\n",
    "        count += 1\n",
    "        total += total\n",
    "\n",
    "\n",
    "print total/count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, we're almost there now: we know _how_ to calculate the mean for any column that is numeric (dealing with non-numeric columns would be nice but it's just adding extra difficulty to this notebook). Now we want to package this up as a function so that you can just write `calcMean(...)` and get back an answer!\n",
    "\n",
    "Here's a skeleton to get you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population\n",
      "9787426\n",
      "2553379\n",
      "2440986\n",
      "1777934\n",
      "1209143\n",
      "864122\n",
      "855569\n",
      "774891\n",
      "729977\n",
      "685368\n",
      "Mean of simple file populations is: 1970799.54545\n"
     ]
    }
   ],
   "source": [
    "def calcMean(data, col):\n",
    "    \"Take a list-of-lists and derive the mean for a specified column.\"\n",
    "    total = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for row in data:\n",
    "        # print(row[col]) # Uncomment to debug\n",
    "        if count == 0: # ???\n",
    "            count += 1\n",
    "        else: \n",
    "            value = float(row[col]) # ???\n",
    "            count += 1\n",
    "            total += value\n",
    "    \n",
    "    return total/count\n",
    "\n",
    "data1 = readRemoteCSV(\"http://www.reades.com/CitiesWithWikipediaData-simple.csv\")\n",
    "print \"Mean of simple file populations is: \" + str(calcMean(data1,5))\n",
    "\n",
    "# Now...\n",
    "\n",
    "data2 = readRemoteCSV(\"http://www.reades.com/CitiesWithWikipediaData.csv\")\n",
    "print \"Mean of big file populations is: \" + str(calcMean(data2,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there you go! Done.\n",
    "\n",
    "You've written two functions: one to read a remote file from a URL, and one to calculate the mean for a simple CSV file of _any_ size. I hope you'll agree that that is pretty handy, but that it's also pretty awkward: we're not doing any type-checking (to see if something is an integer, float, or string) and if we get it wrong the whole thing 'blows up' on us. It's also just kind of _inelegant_ since we have all of these counters (`total` and `count`) to keep track of things... is this what's really going on behind the scenes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking About Data\n",
    "\n",
    "I've said before that the way a computer 'thinks' and the way that we think doesn't always line up naturally. Experienced programmers can think their way _around_ a problem by working _with_ the computer, rather than against it. Let's apply this approach to the parsing of CSV files.\n",
    "\n",
    "## What's an _Appropriate_ Data Structure?\n",
    "\n",
    "As you saw when I asked you to calculate the mean population of British cities twice – once using the simple file, and once using the bigger, more complex file – there is a 'problem': our list-of-lists isn't very easy to navigate. Not only _might_ the location of the Population column be different in the two files (as it was, deliberately), but when we want to work out the mean we need to step through a lot of irrelevant data as well (we need to skip past the name, latitude, longitude, etc.). And if I asked you to find the _largest_ city you'd need to do even more work.\n",
    "\n",
    "So how does the experienced programmer get around this? 'Simple': she realises that the data is organised the wrong way! We humans naturally tend to think in rows of data: London has the following _attributes_ (population, location, etc.), and York has a different set of attributes. Se we read across the row because that's the easiest way for us to read it.\n",
    "\n",
    "But a computer doesn't have to work that way. For a computer, it's as easy to read _down_ a column as it is to read _across_ a row. In fact, it's easier, because each column has a different _type_ of data: so one column contains names (strings), another column contains population (integers), and other columns contain other types of data (floats, etc.). Better still, the order of the columns often doesn't matter as long as we know what they are called: it's easier to ask for the 'population column' than it is to ask for the 6th column since, for all we know, the population column might be in a different place.\n",
    "\n",
    "## A Dictionary of Lists\n",
    "\n",
    "So if we don't mind about column order, only row order (so that we can still link up all of the London data) then a dictionary of lists would be a nice way to handle things. Let's talk this out a bit with some example code, but first, here are the first four rows of data from the simple file:\n",
    "\n",
    "```python\n",
    "['id', 'Name', 'Rank', 'Longitude', 'Latitude', 'Population'], \n",
    "['1', 'Greater London', '1', '-18162.92767', '6711153.709', '9787426'], \n",
    "['2', 'Greater Manchester', '2', '-251761.802', '7073067.458', '2553379'], \n",
    "['3', 'West Midlands', '3', '-210635.2396', '6878950.083', '2440986']\n",
    "```\n",
    "\n",
    "Here's how it would look as a dictionary of lists organised by _column_, not by row:\n",
    "\n",
    "```python\n",
    "myData = {\n",
    "    'id'         : [1, 2, 3],\n",
    "    'Name'       : ['London', 'Manchester', 'West Midlands'],\n",
    "    'Rank'       : [1, 2, 3],\n",
    "    'Longitude'  : [-18162.92767, -251761.802, -210635.2396],\n",
    "    'Latitude'   : [6711153.709, 7073067.458, 6878950.083],\n",
    "    'Population' : [9787426, 2553379, 2440986],\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "What does this do better? Well, for starters, we know that everything in the 'Name' column will be a string, and that everything in the 'Longitude' column is a float, while the 'Population' column contains integers. So that's made life easier already. But let's test this out and see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The population of Manchester is: 2553379\n",
      "The westernmost city is: London\n",
      "The mean population is: 4927263.66667\n"
     ]
    }
   ],
   "source": [
    "myData = {\n",
    "    'Name'       : ['London','Manchester','West Midlands'],\n",
    "    'Rank'       : [1, 2, 3, 4],\n",
    "    'Longitude'  : [-18162.92767, -251761.802, -210635.2396],\n",
    "    'Latitude'   : [6711153.709, 7073067.458, 6878950.083],\n",
    "    'Population' : [9787426, 2553379, 2440986],\n",
    "}\n",
    "\n",
    "# Find the population of Manchester\n",
    "pop = myData['Population'][myData['Name'].index('Manchester')]\n",
    "print \"The population of Manchester is: \" + str(pop)\n",
    "\n",
    "# Find the westernmost city\n",
    "city = myData['Name'][myData['Longitude'].index(max(myData['Longitude']))]\n",
    "print \"The westernmost city is: \" + str(city)\n",
    "\n",
    "# Find the mean population of the cities\n",
    "import numpy as np # Need to import a useful package\n",
    "mean = np.mean(myData['Population'])\n",
    "print \"The mean population is: \" + str(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review!\n",
    "\n",
    "There's a _lot_ of content to process in the code above, so do _not_ rush blindly on if this is confusing. Stop. Think it through. We'll go through each one in turn, but they nearly all work in the same way.\n",
    "\n",
    "### The Population of Manchester\n",
    "\n",
    "The code can look pretty daunting, so let's break it down into two parts.\n",
    "\n",
    "What would you get if you ran just this code?\n",
    "```python\n",
    "myData['Population'][0]\n",
    "```\n",
    "Remember that this is a dictionary-of-lists (DoL). So, Python first looks for a key named `Population` in the myData dictionary. It finds out that the value associated with this key is a _list_ (`[9787426, 2553379, 2440986]`). And this example, it just pulls out the first value (index 0), which is `9787426`. Does that make sense?\n",
    "\n",
    "Now, to the second part:\n",
    "```python\n",
    "myData['Name'].index('Manchester')\n",
    "\n",
    "```\n",
    "This is very similar: we look in the dictionary for the key `Name` and find that that's _also_ a list (`['London','Manchester','West Midlands']`, since you asked). If you don't remember what `index` does, don't worry, here's the output from Python's `help()` function:\n",
    "```\n",
    "Help on built-in function index:\n",
    "\n",
    "index(...)\n",
    "    L.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
    "    Raises ValueError if the value is not present.\n",
    "```\n",
    "So all we're doing is asking Python to find out the index of 'Manchester' in the list associated with the dictionary key 'Name' _instead_ of just sticking in a `0` to get the first index value. Putting these two things back together what we're doing is:\n",
    "* Finding the index of 'Manchester' in the Name column,\n",
    "* Using that index to read a value out of the Population column.\n",
    "\n",
    "Does that make sense? If it does then you should be having a kind of an Alice-through-the-Looking-Glass moment.\n",
    "\n",
    "### The Westernmost City\n",
    "\n",
    "Where this approach really comes into its own is on problems that involve maths. To figure out the westernmost city in this list we need to find the _maximum_ Longitude and then use _that_ to look up the right city. So let's do the same process of pulling this appart into two steps:\n",
    "\n",
    "It should be _pretty_ obvious what this does:\n",
    "```python\n",
    "myData['Name'][0]\n",
    "```\n",
    "But we don't just want the first city in the list, we want the one with the highest longitude. So to achieve that we need to replace the `0` with an index that we found by looking in the `Longitude` list.\n",
    "```python\n",
    "myData['Longitude'].index(max(myData['Longitude']))\n",
    "\n",
    "```\n",
    "Ugh, that's still a little hard to read, isn't it? Let's break it down differently:\n",
    "\n",
    "```python\n",
    "myData['Longitude'].index(\n",
    "    max(myData['Longitude'])\n",
    ")\n",
    "\n",
    "```\n",
    "There's the same `.index` which tells us that Python is going to look for something in the list associated with the `Longitude` key. All we've done is change what's _inside_ that index function: `max(myData['Longitude'])` is telling Python to find the _maximum_ value in the `myData['Longitude']` list. So to explain this in three steps, what we're doing is:\n",
    "* Finding the maximum value in the Longitude column (we know the value, we don't know where it is!),\n",
    "* Finding the index (position) of that value in the Longitude column (now we know where it is!),\n",
    "* Using that index to read a value out of the Name column.\n",
    "\n",
    "I am a nerd, but that's pretty cool, right? In one line of code we managed to quickly find out where the data we needed was even though it involved three discrete steps. Remember how much work it was to find the mean when you were still thinking in _rows_, not _columns_?\n",
    "\n",
    "### The Average City Size\n",
    "\n",
    "Yeah, let's try that too.\n",
    "\n",
    "Here we're going to 'cheat' a little bit: rather than writing our own function, we're going to import a package and use someone _else's_ function. The `numpy` package contains a _lot_ of useful functions that we can call on (if you don't believe me, add `dir(np)` after the `import` statement), and one of them calculates the average of a list or array of data.\n",
    "```python\n",
    "import numpy as np # Need to import a useful package\n",
    "mean = np.mean(myData['Population'])\n",
    "```\n",
    "This is where our new approach really comes into its own: because all of the data in that _series_ (i.e. column) is in one place, we can just throw the whole thing into the `np.mean` function rather than hyaving to use all of those convoluted loops and counters. Simples, right?\n",
    "\n",
    "### Standard Devision\n",
    "\n",
    "By using `numpy` can you figure out how to modify the code above to look at the standard deviation instead of the mean? You might need a refresher as to how to calculate the standard deviation: http://www.mathsisfun.com/data/standard-deviation.html\n",
    "\n",
    "## Review!\n",
    "\n",
    "So the _really_ clever bit in all of this isn't switching from a list-of-lists to a dictionary-of-lists, it's recognising that the latter is a _better_ way to work _with_ the data that we're trying to analyse and that that there are useful functions that we can exploit to do the heavy lifting for us. Simply be changing the way that we stored the data in a 'data structure' (i.e. complex arrangement of lists, dictionaries, and variables) we were able to do away with lots of for loops and counters and conditions, and reduce many difficult operations to something that could be done on one line! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting a Number\n",
    "\n",
    "A final, handy trick if you want to output numbers in a _pretty_ way is to understand how the `format` method associated with string objects works: different cultures format numbers differently, so the English use commas as the thousands separator and a full-stop as the decimal separator but the French, naturally, do it their own way.\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,927,263.67\n",
      "4 927 263,67\n"
     ]
    }
   ],
   "source": [
    "print \"{:,.2f}\".format(mean)\n",
    "\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'fr_FR')\n",
    "print locale.format('%0.2f', mean, grouping=True, monetary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, most programming languages were written by Anglophones and so most applications will happily output Anglo-formatted numbers but are rather less happy doing anyone else's.\n",
    "\n",
    "More on `format` in the _Python String Format Cookbook_: https://mkaz.tech/python-string-format.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
