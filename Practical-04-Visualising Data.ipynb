{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "<h1>Visualising Data</h1>\n",
    "<h2>7SSG2059 Geocomputation 2016/17</h2>\n",
    "<h3>_Jon Reades_</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Week’s Overview\n",
    "\n",
    "This week we're going to explore how visualising data (using pandas and seaborn) helps us to make more sense of our data. We're then going to move on to automating this process because coding isn't _just_ about being able to load lots of data, it's also about being able to be constructively lazy with the data once it's loaded.\n",
    "\n",
    "## Learning Outcomes\n",
    "\n",
    "By the end of this practical you should:\n",
    "- Have created a set of different plots using Seaborn\n",
    "- Have automated the presentation of data for a number of columns\n",
    "- Have grasped how a mix of graphs and numbers can help you make sense of your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working through the Data\n",
    "\n",
    "Last week you downloaded the `listings.csv` file since it's quite a bit smaller and easier to work with. Today, we're going to load the full data set, which contains 95 columns, instead of 'just' 16. This will allow us to investigate some of the metrics in more detail using graphical plots.\n",
    "\n",
    "_Note:_ notice that there is a 'show archived data' link containing older data for each city on the [Get the Data](http://insideairbnb.com/get-the-data.html) page... think that could be useful for something???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame shape: (4835, 43)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\n",
    "    'https://github.com/kingsgeocomp/geocomputation/blob/master/Data/LSOA%20Data.csv.gz?raw=true',\n",
    "    compression='gzip', low_memory=False) # The 'low memory' option means pandas doesn't guess data types\n",
    "print(\"Data frame shape: \" + str(df.shape)) # What is the shape of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>MSOA11CD</th>\n",
       "      <th>MSOA11NM</th>\n",
       "      <th>LAD11CD</th>\n",
       "      <th>LAD11NM</th>\n",
       "      <th>RGN11CD</th>\n",
       "      <th>RGN11NM</th>\n",
       "      <th>USUALRES</th>\n",
       "      <th>...</th>\n",
       "      <th>Sum Price</th>\n",
       "      <th>Mean Price</th>\n",
       "      <th>Median Price</th>\n",
       "      <th>Entire home/apt</th>\n",
       "      <th>Private room</th>\n",
       "      <th>Shared room</th>\n",
       "      <th>Small Host</th>\n",
       "      <th>Multiple Location Host</th>\n",
       "      <th>Property Count</th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>London</td>\n",
       "      <td>1465</td>\n",
       "      <td>...</td>\n",
       "      <td>2589.0</td>\n",
       "      <td>152.294118</td>\n",
       "      <td>146.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>133320.768859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>E01000002</td>\n",
       "      <td>City of London 001B</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>London</td>\n",
       "      <td>1436</td>\n",
       "      <td>...</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>149.833333</td>\n",
       "      <td>117.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>226191.273063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   LSOA11CD             LSOA11NM   MSOA11CD            MSOA11NM  \\\n",
       "0           0  E01000001  City of London 001A  E02000001  City of London 001   \n",
       "1           1  E01000002  City of London 001B  E02000001  City of London 001   \n",
       "\n",
       "     LAD11CD         LAD11NM    RGN11CD RGN11NM  USUALRES      ...        \\\n",
       "0  E09000001  City of London  E12000007  London      1465      ...         \n",
       "1  E09000001  City of London  E12000007  London      1436      ...         \n",
       "\n",
       "   Sum Price  Mean Price  Median Price  Entire home/apt  Private room  \\\n",
       "0     2589.0  152.294118         146.0             14.0           1.0   \n",
       "1     2697.0  149.833333         117.5             12.0           5.0   \n",
       "\n",
       "  Shared room  Small Host  Multiple Location Host  Property Count  \\\n",
       "0         2.0        11.0                     6.0            17.0   \n",
       "1         1.0        13.0                     5.0            18.0   \n",
       "\n",
       "            Area  \n",
       "0  133320.768859  \n",
       "1  226191.273063  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look at some data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'LSOA11NM', u'MSOA11CD', u'MSOA11NM', u'LAD11CD', u'LAD11NM',\n",
       "       u'RGN11CD', u'RGN11NM', u'USUALRES', u'HHOLDRES', u'COMESTRES',\n",
       "       u'POPDEN', u'HHOLDS', u'AVHHOLDSZ', u'geometry',\n",
       "       u'Area that is Designated Greenspace',\n",
       "       u'Area within 250m of M or A Roads', u'Owned',\n",
       "       u'Shared ownership (part owned and part rented)', u'Social rented',\n",
       "       u'Private rented', u'Living rent free',\n",
       "       u'Occupancy rating (rooms) of -1 or less',\n",
       "       u'Occupancy rating (bedrooms) of -1 or less',\n",
       "       u'Average number of rooms per household',\n",
       "       u'Average number of bedrooms per household', u'White',\n",
       "       u'Mixed/multiple ethnic groups', u'Asian/Asian British',\n",
       "       u'Black/African/Caribbean/Black British', u'Other ethnic group',\n",
       "       u'Median Income', u'Sum Price', u'Mean Price', u'Median Price',\n",
       "       u'Entire home/apt', u'Private room', u'Shared room', u'Small Host',\n",
       "       u'Multiple Location Host', u'Property Count', u'Area'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# That looks like a lot of columns!\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Save this locally to avoid having to re-download it every time we start this notebook\n",
    "df.to_csv('lsoa.csv.gz', compression='gzip', index=False)\n",
    "\n",
    "# Delete the variable to avoid confusion later\n",
    "del(df)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry about the `index=False` parameter, but what do you think is going on with `compression='gzip'`? Can you find what _other_ options are supported for compression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Working with Really Big Data Sets\n",
    "\n",
    "The London [InsideAirBnB data](http://insideairbnb.com/get-the-data.html) is nearly 50MB -- reading and loading that amount of data will slow things down quite a bit! Sometimes it's easier to work with only a portion of the data while we are doing our coding and then, once we know that we've written things correctly, we do our analysis on the whole data set. \n",
    "\n",
    "One way to achieve this right at the start is to specify the number of rows (abbreviated to `nrows`) that you want to load. Using our LSOA data set, for instance, do we really need to start out with all 4,300 rows? Or could we work with 'just' 2,000 to get things started? If we use functions to automate our analysis then the answer is: it doesn't matter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4835, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>MSOA11CD</th>\n",
       "      <th>MSOA11NM</th>\n",
       "      <th>LAD11CD</th>\n",
       "      <th>LAD11NM</th>\n",
       "      <th>RGN11CD</th>\n",
       "      <th>RGN11NM</th>\n",
       "      <th>USUALRES</th>\n",
       "      <th>HHOLDRES</th>\n",
       "      <th>...</th>\n",
       "      <th>Sum Price</th>\n",
       "      <th>Mean Price</th>\n",
       "      <th>Median Price</th>\n",
       "      <th>Entire home/apt</th>\n",
       "      <th>Private room</th>\n",
       "      <th>Shared room</th>\n",
       "      <th>Small Host</th>\n",
       "      <th>Multiple Location Host</th>\n",
       "      <th>Property Count</th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>London</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>...</td>\n",
       "      <td>2589.0</td>\n",
       "      <td>152.294118</td>\n",
       "      <td>146.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>133320.768859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E01000002</td>\n",
       "      <td>City of London 001B</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>City of London 001</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>London</td>\n",
       "      <td>1436</td>\n",
       "      <td>1436</td>\n",
       "      <td>...</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>149.833333</td>\n",
       "      <td>117.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>226191.273063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LSOA11CD             LSOA11NM   MSOA11CD            MSOA11NM    LAD11CD  \\\n",
       "0  E01000001  City of London 001A  E02000001  City of London 001  E09000001   \n",
       "1  E01000002  City of London 001B  E02000001  City of London 001  E09000001   \n",
       "\n",
       "          LAD11NM    RGN11CD RGN11NM  USUALRES  HHOLDRES      ...        \\\n",
       "0  City of London  E12000007  London      1465      1465      ...         \n",
       "1  City of London  E12000007  London      1436      1436      ...         \n",
       "\n",
       "   Sum Price  Mean Price  Median Price  Entire home/apt Private room  \\\n",
       "0     2589.0  152.294118         146.0             14.0          1.0   \n",
       "1     2697.0  149.833333         117.5             12.0          5.0   \n",
       "\n",
       "   Shared room  Small Host  Multiple Location Host  Property Count  \\\n",
       "0          2.0        11.0                     6.0            17.0   \n",
       "1          1.0        13.0                     5.0            18.0   \n",
       "\n",
       "            Area  \n",
       "0  133320.768859  \n",
       "1  226191.273063  \n",
       "\n",
       "[2 rows x 42 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('lsoa.csv.gz', index_col=0, nrows=4835) # Try changing the nrows value\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see a lot more with James in how to more effectively subset and sample data, but this should speed things up quite a bit until we're ready to deal with the whole data set!\n",
    "\n",
    "**Q1.** Can you spot the difference between the output of the _original_ `df.head(2)` and the _new_ one that we just loaded? _Hint:_ we've added a new parameter _besides_ `nrows`. We'll be looking at this in more detail next week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Data\n",
    "\n",
    "Let's start with some really obvious questions about the data. We looked at distributions and min/max issues using built-in pandas functions the previous week, but that doesn't tell us _which_ places are very expensive/large/whatever. \n",
    "\n",
    "One way that we can tackle that is to describe the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4067.000000\n",
       "mean       76.080286\n",
       "std        51.979531\n",
       "min         9.000000\n",
       "25%        45.309524\n",
       "50%        66.000000\n",
       "75%        94.228448\n",
       "max      1208.333333\n",
       "Name: Mean Price, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Mean Price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to 'sanity check' is to sort the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Price</th>\n",
       "      <th>LSOA11NM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E01002611</th>\n",
       "      <td>1208.333333</td>\n",
       "      <td>Hounslow 024D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01001313</th>\n",
       "      <td>1034.750000</td>\n",
       "      <td>Ealing 002D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01003809</th>\n",
       "      <td>925.833333</td>\n",
       "      <td>Richmond upon Thames 005D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01004745</th>\n",
       "      <td>645.967742</td>\n",
       "      <td>Westminster 021C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01003377</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>Merton 012C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Mean Price                   LSOA11NM\n",
       "LSOA11CD                                         \n",
       "E01002611  1208.333333              Hounslow 024D\n",
       "E01001313  1034.750000                Ealing 002D\n",
       "E01003809   925.833333  Richmond upon Thames 005D\n",
       "E01004745   645.967742           Westminster 021C\n",
       "E01003377   500.000000                Merton 012C"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='Mean Price', ascending=False).head(5)[['Mean Price','LSOA11NM']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That last command is actually quite complex, so let's take a second to unpack it:\n",
    "```python\n",
    "df.sort_values(by='Mean Price', ascending=False).head(5)[['Mean Price','LSOA11NM']]\n",
    "```\n",
    "\n",
    "1. Take the data frame `df`;\n",
    "2. Sort it using the `Mean Price` column by descending order (_i.e._ `ascending=False`);\n",
    "3. Take the first five values (`head(5)`);\n",
    "4. And print out the columns specified by the list (`['Mean Price','LSOA11NM']`).\n",
    "\n",
    "Let's pull it apart step-by-step at the code level:\n",
    "\n",
    "* The first step in this process is `df.sort_values` -- you can probably guess what this does: it sorts the data frame!\n",
    "* The parameters passed to the `sort_values(...)` function are `by`, which is the column on which to sort, and `ascending=False`, which gives us the data frame sorted in _descending_ order!\n",
    "* The output of `df.sort(...)` is _itself_ a new data frame, which means that we can simply add `.head(5)` to get the first five rows of the newly-sorted data frame.\n",
    "* And the output of `df.sort(...).head(...)` is yet _another_ data frame, which means that we can print out the values of selected columns using the 'dictionary-like' syntax: we use the outer set of square brackets (`[...]`) to tell pandas that we want to access a subset of the top-5 data frame, and we use the inner set of square brackets (`['Mean Price','LSOA11NM']`) to tell pandas which columns we want to see.\n",
    "\n",
    "I'd say 'simples, right?' but that's obviously _not_ simple. It _is_, however, very, very _elegant_ because it's quite clear (once you get past the way that lots of commands can be chained together) and it's very succinct (we did all of that in _one_ line of code!).\n",
    "\n",
    "**Q2.** Now, can you output the Mean and Median prices (as well as the LSOA11NM) for the 7 _cheapest (by median price)_ LSOAs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Price</th>\n",
       "      <th>Median Price</th>\n",
       "      <th>LSOA11NM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E01003484</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Newham 032B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01000192</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Barnet 018A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01000083</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Barking and Dagenham 007F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01002645</th>\n",
       "      <td>19.777778</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Hounslow 015C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01002642</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Hounslow 015A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01001675</th>\n",
       "      <td>15.333333</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Greenwich 006D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01002648</th>\n",
       "      <td>32.916667</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Hounslow 018C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean Price  Median Price                   LSOA11NM\n",
       "LSOA11CD                                                      \n",
       "E01003484    9.000000           9.0                Newham 032B\n",
       "E01000192   12.000000          12.0                Barnet 018A\n",
       "E01000083   28.000000          12.0  Barking and Dagenham 007F\n",
       "E01002645   19.777778          13.0              Hounslow 015C\n",
       "E01002642   13.000000          13.0              Hounslow 015A\n",
       "E01001675   15.333333          13.0             Greenwich 006D\n",
       "E01002648   32.916667          13.0              Hounslow 018C"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(???).???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all has gone well (using the full data set) you should have:\n",
    "\n",
    "| LSOACD | Mean Price | Median Price | LSOA11NM |\n",
    "|--------|------------|--------------|----------|\t\n",
    "| E01003484 | 9.000000 | 9.0 | Newham 032B |\n",
    "| E01000192 | 12.000000 | 12.0 | Barnet 018A |\n",
    "| E01000083 | 28.000000 | 12.0 | Barking and Dagenham 007F |\n",
    "| E01002645 | 19.777778 | 13.0 | Hounslow 015C |\n",
    "| E01002642 | 13.000000 | 13.0 | Hounslow 015A |\n",
    "| E01001675 | 15.333333 | 13.0 | Greenwich 006D |\n",
    "| E01002648 | 32.916667 | 13.0 | Hounslow 018C |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with a Data Series\n",
    "\n",
    "Implicitly, we've already done quite a bit with the Series (i.e. column) class offered by pandas, but I want to revisit it so that you understand why getting to grips with how the series works (especially the 'index', which is a special type of series) is crucial to getting the most out of pandas.\n",
    "\n",
    "The easiest way to think about this: a `Series` is just another name for a pandas column.\n",
    "\n",
    "### Adding a New Series\n",
    "\n",
    "You may recall that you can add a new series to an existing data frame using the dictionary-like syntax:\n",
    "```python\n",
    "df['<new series name>'] = pd.Series(... <series definition> ...)\n",
    "``` \n",
    "But just to remind you: see how familiar that syntax is? `df['key'] = value` is _exactly_ like creating and assigning a new key/value pair to a dictionary called `df`! The only difference here is that the 'value' we store in the dictionary is a Series object, and not a simple variable (String, int, float).\n",
    "\n",
    "Let's do this for the price so that we get a sense of how expensive a place is _relative_ to all other listings... Perhaps something like standard deviations from the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['score'] = pd.Series((df['Mean Price'] - df['Mean Price'].mean()) / df['Mean Price'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4.067000e+03\n",
       "mean     1.397674e-16\n",
       "std      1.000000e+00\n",
       "min     -1.290514e+00\n",
       "25%     -5.919785e-01\n",
       "50%     -1.939280e-01\n",
       "75%      3.491406e-01\n",
       "max      2.178267e+01\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.score.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's step through the code to make sense of what we just did:\n",
    "```python\n",
    "series = pd.Series((df.price - df.price.mean()) / df.price.std())\n",
    "```\n",
    "That doesn't look _exactly_ the same, but that's only because our column name has a space in it ('Mean Price'). If it were 'mean_price' or, more simply, 'price' then we could use the easier-to-read syntax above.\n",
    "\n",
    "Aaaaanyway:\n",
    "1. `pd.Series(...)` creates a new pandas Series from whatever data we pass it;\n",
    "2. `(df.price - df.price.mean())` does something really clever: it takes each _individual_ row value of the `price` column and _subtracts_ the average price of the entire column using `df.price.mean()`.\n",
    "3. We then divide that by the standard deviation, which we just calculated for the _entire_ column using `df.price.std()`!\n",
    "\n",
    "Doing this in Excel would be a bit more work and, more importantly, a _lot_ slower. This is especially true if what you want to do is get things working on a subset of the data _before_ analysing the entire data set in one go. Imagine doing this for 25,000,000 records and you begin to see how _scripability_ is incredibly useful here.\n",
    "\n",
    "**Q3.** What's the statistical term for what we've just calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's in a Score?\n",
    "\n",
    "Do you remember any GCSE statistics? What this pandas command does:\n",
    "```python\n",
    "(df.price - df.price.mean()) / df.price.std()\n",
    "```\n",
    "\n",
    "...is standardisation (more on this near the end of term):\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\bar x}{\\sigma}\n",
    "$$\n",
    "\n",
    "The number that we have now tells us how far from the _average_ price of properties in London _each_ individual property is as a multiple of the standard deviation. So something priced at the average would have a value of `0`, while the most expensive are many times that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Price</th>\n",
       "      <th>score</th>\n",
       "      <th>LSOA11NM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E01001125</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Croydon 033E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01001116</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>-0.713363</td>\n",
       "      <td>Croydon 013F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01003222</th>\n",
       "      <td>41.666667</td>\n",
       "      <td>-0.662061</td>\n",
       "      <td>Lewisham 022D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01004161</th>\n",
       "      <td>84.500000</td>\n",
       "      <td>0.161981</td>\n",
       "      <td>Sutton 014E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01002992</th>\n",
       "      <td>53.333333</td>\n",
       "      <td>-0.437614</td>\n",
       "      <td>Kingston upon Thames 010D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01002416</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>-0.886508</td>\n",
       "      <td>Hillingdon 008A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01000162</th>\n",
       "      <td>78.666667</td>\n",
       "      <td>0.049758</td>\n",
       "      <td>Barnet 015E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01002063</th>\n",
       "      <td>120.500000</td>\n",
       "      <td>0.854562</td>\n",
       "      <td>Haringey 036B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01000469</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bexley 001D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E01000260</th>\n",
       "      <td>98.666667</td>\n",
       "      <td>0.434525</td>\n",
       "      <td>Barnet 025E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean Price     score                   LSOA11NM\n",
       "LSOA11CD                                                  \n",
       "E01001125         NaN       NaN               Croydon 033E\n",
       "E01001116   39.000000 -0.713363               Croydon 013F\n",
       "E01003222   41.666667 -0.662061              Lewisham 022D\n",
       "E01004161   84.500000  0.161981                Sutton 014E\n",
       "E01002992   53.333333 -0.437614  Kingston upon Thames 010D\n",
       "E01002416   30.000000 -0.886508            Hillingdon 008A\n",
       "E01000162   78.666667  0.049758                Barnet 015E\n",
       "E01002063  120.500000  0.854562              Haringey 036B\n",
       "E01000469         NaN       NaN                Bexley 001D\n",
       "E01000260   98.666667  0.434525                Barnet 025E"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='score', ascending=False).sample(10)[['Mean Price','score','LSOA11NM']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** Using the output of the `sample(10)` function can you guess about what the mean price of an Airbnb property in London might be?\n",
    "\n",
    "Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.080286011816909"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Mean Price'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Data\n",
    "\n",
    "OK, we've added one useful new column (data series) to our data frame just to see how it's done, but now let's get down to some visualisation!\n",
    "\n",
    "### Start with a Chart\n",
    "\n",
    "If we weren't learning how to program at the same time as we learn to do data analysis then my recommendation would have been this: **start with a chart**. Of course, we mean start with a _good_ chart:\n",
    "\n",
    "[![Do maps lie?](http://img.youtube.com/vi/hYaoE4Kh9fk/0.jpg)](http://www.youtube.com/watch?v=hYaoE4Kh9fk)\n",
    "\n",
    "There is _no_ better tool for understanding what is going on in your data than to visualise it, but we couldn't show you how to make a plot without first teaching you how to load data and perform some basic operations on a data frame! \n",
    "\n",
    "Now that we've done *that*, we can get to grips with VDQI (the [Visual Display of Quantitative Information](https://www.edwardtufte.com/tufte/books_vdqi) and how this supports our understanding of the data.\n",
    "\n",
    "### Why Seaborn?\n",
    "\n",
    "We can do some straightforward plotting directly from pandas, but for the data visualisation part of the practical we are going to use the [Seaborn package](http://stanford.edu/~mwaskom/software/seaborn/) because it provides a lot of quite complex functionality (and very pretty graphs) at quite low 'cost' (_i.e._ effort). There are, however, other options out there that are worth checking out if you take things further; the two that you are most likely to hear mentioned are: [Bokeh](http://bokeh.pydata.org/en/latest/) and matplotlib. \n",
    "\n",
    "1. Bokeh is, like, Seaborn designed to make it easy for you to create good-looking plots with minimal effort. \n",
    "2. Matplotlib is a different beast: it is actually the _underlying_ package that supports the majority of plotting (drawing graphs) in Python. \n",
    "\n",
    "So Seaborn and Bokeh both make use of the matplotlib library to create their plots, and if you want to customise a figure from either of these two libraries then you will eventually need to get to grips with matplotlib. The reason we don't teach matplotlib directly is that it's much harder to make a good plot and the syntax is much more complex.\n",
    "\n",
    "A more recent entrant is yhat's (a data science 'joke') ggplot library, which deliberately mimics R’s ggplot2 (http://ggplot.yhathq.com) -- this library has become the dominant way of creating plots in the R programming language and it uses a 'visualisation' grammar that many people find incredibly powerful and highly customisable. Unfortunately, ggplot on Python does not currently support mapping (which R does in ggplot2).\n",
    "\n",
    "### Loading Seaborn \n",
    "\n",
    "As with other libraries that we’ve used, we’ll import Seaborn using an alias:\n",
    "```python\n",
    "import seaborn as sns\n",
    "```\n",
    "So to access Seaborn's functions we will now always just write `sns.<function name>()` (where `<function name>` would be something like `distplot`). \n",
    "\n",
    "### But First!\n",
    "\n",
    "<span style=\\\"color:red;\\\">Important Note for Mac Users</span>\n",
    "\n",
    "Recent changes in the way that the Mac OS handles the plotting of data means that you need to do certain things in a specific order at the start of any notebook in which you intend to show maps or graphs. Please make a copy of the following code for any notebook that you create and make it the _first_ code that you run in the notebook:\n",
    "\n",
    "```python\n",
    "# Needed on a Mac\n",
    "import matplotlib as mpl\n",
    "mpl.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "For non-Mac users it _should_ be:\n",
    "```python\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "This _should_ enable you to create plots, including in the practical that we're about to start! If you forget to run this code _before_ trying to use Seaborn then you will probably need to restart the Kernel (Kernel > Restart from the menu). If you do _that_ you will lose all of your 'live' work (_i.e._ variables, loaded modules, etc.).\n",
    "\n",
    "The `%matplotlib inline` command only need to be run _once_ in a jupyter notebook; it tells jupyter to show the plots as part of the web page, rather than trying to show them in a separate window. So the easiest thing to do is just stick whatever code you need at the top of your notebook so that you _always_ run it once when you start up a notebook and can then forget about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/gsa2017/lib/python2.7/site-packages/matplotlib/__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "# Needed on a Mac\n",
    "import matplotlib as mpl\n",
    "mpl.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Distribution Plot\n",
    "\n",
    "One of the most useful ways to get a sense of a data series is simply to look at its overall distribution. Something like this:\n",
    "```python\n",
    "sns.distplot(<data series>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8252eae7f454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Note the x-axis range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Mean Price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/envs/gsa2017/lib/python2.7/site-packages/seaborn/distributions.pyc\u001b[0m in \u001b[0;36mdistplot\u001b[0;34m(a, bins, hist, kde, rug, fit, hist_kws, kde_kws, rug_kws, fit_kws, color, vertical, norm_hist, axlabel, label, ax)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_freedman_diaconis_bins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mhist_kws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mhist_kws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"normed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/gsa2017/lib/python2.7/site-packages/seaborn/distributions.pyc\u001b[0m in \u001b[0;36m_freedman_diaconis_bins\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117d4c6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note the x-axis range\n",
    "sns.distplot(df['Mean Price'], hist=False)\n",
    "sns.distplot(df['Median Price'], hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note the x-axis range!\n",
    "sns.distplot(df.score, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all at went well you should see an 'ok' (kind of 'meh', really) distribution plot for the price! Let's try it *after* removing listings with z-scores greater than 8 instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note the x-axis range!\n",
    "# Note the switch from a histogram to a KDE\n",
    "# What else can you do...\n",
    "#?sns.distplot\n",
    "sns.distplot(df.price[df.score.abs() < 5], hist=False, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "\n",
    "OK, I want you to take a second here: although there was a lot of setup work that needed to be done, we just created a distribution plot in one line of code _after_ filtering out values that we felt were skewing our view of the data. _One line_. This is a more sophisticated plot than you could ever create in Excel and you just created it in one line of code!\n",
    "\n",
    "Let's review:\n",
    "```python\n",
    "sns.distplot(df.price[df.score.abs() < 5])\n",
    "```\n",
    "We are:\n",
    "1. Creating a seaborn distribution plot (`sns.distplot(...)`)\n",
    "2. Using the price column (`df.price`)\n",
    "3. But first selecting only those data where the absolute value of the standard deviation was less than 8 (`df.stdev.abs() < 5`).\n",
    "\n",
    "You'll notice too that list-type syntax: `df.price[...]` which tells us that we're selecting elements of the list in the same way that we selected column names above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automation\n",
    "\n",
    "Try producing similar plots for some of the other groups. You should be able to do this using two things:\n",
    "* A `for` loop to iterate over the column names\n",
    "* String interpolation to access the column in the data frame\n",
    "\n",
    "How about we try: `'bathrooms', 'bedrooms', 'beds', 'square_feet', 'price', 'weekly_price'`?\n",
    "\n",
    "I'll get you started... this also demonstrates how we can use pandas' dictionary-style notation to create a new string that we can then use as a key for a new data series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in ???:\n",
    "    plt.figure() # Create a new figure so they don't over-print\n",
    "    sns.distplot(df[???], hist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have 5 charts and an error. \n",
    "\n",
    "**Q4.** Which column failed to plot and why? How would you fix it?\n",
    "\n",
    "And did you notice how we turned off the histogram (which would have been confusing with 8 overlapping plots) using the `hist=False` option? More on this, as always, using `help(sns.distplot)` or [RTM](https://seaborn.github.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix the error using this coding area\n",
    "# and copy+paste the for loop as well to\n",
    "# test that you've corrected it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a Plot\n",
    "\n",
    "But... wouldn’t be it a lot easier if we could save our plot automatically and not have to even touch a button to do so? This is where we need to use matplotlib syntax (and where you'll see why we opted not to spend too much time on it):\n",
    "\n",
    "```python\n",
    "series = df.price \n",
    "fig = plt.figure(series.name)\n",
    "sb.distplot(series)\n",
    "fig = plt.gcf()\n",
    "plt.savefig(\"{0}-Test.pdf\".format(series.name), bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "```\n",
    "\n",
    "To explain what's happening here: \n",
    "\n",
    "1. We import a sub-package of `matplotlib` that gives us access to all kind of useful functions (We've actually done this already, which is why this line is commented out).\n",
    "2. We copy the price data series to a new variable (this would mean that, to print out weekly_price or monthly_price we'd only have to change this one line... see: we're preparing to use a `for` loop!)\n",
    "3. We create a `figure` object into which Seaborn can 'print' its outputs.\n",
    "4. We call Seaborn and ask it to print (it doesn't really need to know that it's printing to something, it just nees to know what 'device' is should use for output).\n",
    "5. We save the plot, using the `format` command to replace the `{0}` with the name of the data series (so in this example we'd be saving our figure to `price-Test.pdf`).\n",
    "6. We then close the figure output so that we don't print other plots over top of it -- that's what happened in the earlier code when we used the `for` loop!\n",
    " \n",
    "The plot should have been saved to your working directory (where the Jupyter notebook is running) using the name of the data series that you were working with. We want to use string replacement (the `{0}`) so that when we save the plot for weekly_price or monthly_price we don't overwrite the one for price!\n",
    "\n",
    "Let's try saving the square footage data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series = ???                  # Copy the square footage data series to a new variable\n",
    "fig = plt.figure(series.name) # Create a figure using a title based on the series name\n",
    "sns.distplot(series)          # Plot the series to the open 'figure' device\n",
    "fig = plt.gcf()               # *G*et the *C*urrent *F*igure environment so that the next command works\n",
    "plt.savefig(\"{0}-Test.pdf\".format(series.name), bbox_inches=\"tight\")\n",
    "plt.close()                   # Close the plot so that nothing else overwrites our work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automation with Loops & Functions\n",
    "\n",
    "When we're undertaking an analysis of a data set, we often have to perform the same (or at least similar) tasks for each weather station or socio-economic class or ethnic group. We *could* copy and paste the code, and then just change the variable names to update the analysis... but that would be a definite instance of what Larry Wall would have called 'false laziness': it seems like a time-saving device in the short run, but in the long run you've made your code less readily maintainable (what if you want to _add_ to your analysis or find a bug?) and less easy to understand.\n",
    "\n",
    "There are nearly always two things that you should look at if you find yourself repeating the same code: \n",
    "1. write a for loop; \n",
    "2. consider writing a function.\n",
    "\n",
    "**Q5.** Why do you think that we use these two strategies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a For Loop\n",
    "\n",
    "Let’s start with a for loop to generate summary statistics for several of our data columns -- you’ve already typed all of this code more than once so all we need to do is take the right bits of it and put them in a for loop like this:\n",
    "```python\n",
    "for c in ...:\n",
    "    series = df[c] # Get the series\n",
    "    print('Sumarising ' + series.name)\n",
    "    print(\"\\tMean:    {0:> 9.2f}\".format(series.mean()))\n",
    "    print(\"\\tMedian:  {0:> 9.2f}\".format(series.median()))\n",
    "```\n",
    " \n",
    "All you need to do is figure out which data series go into the for loop in the first place and then your code will run for each one, producing a nicely formatted summary for each... we hope!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    series = df[c]\n",
    "    print('Sumarising ' + series.name)\n",
    "    print(\"\\tMean:    {0:> 9.2f}\".format(series.mean()))\n",
    "    print(\"\\tMedian:  {0:> 9.2f}\".format(series.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as you've just now discovered you can't do this for every column because not every one is numeric, so it's time to introduce a useful little 'emergency' handler for what Python calls '[exceptions](https://docs.python.org/2/tutorial/errors.html)':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in df.columns[56:62]: # Notice that we start with some testing!!!\n",
    "    series = df[c]\n",
    "    print('Summarising ' + series.name)\n",
    "    try:              # Try to do something\n",
    "        print(\"\\tMean:    {0:> 9.2f}\".format(series.mean()))\n",
    "        print(\"\\tMedian:  {0:> 9.2f}\".format(series.median()))\n",
    "    except TypeError: # If you see this problem don't blow up please!\n",
    "        print(\"\\tData cannot be summarised numerically.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare that output with the output below and then answer this question:\n",
    "\n",
    "**Q6.** Why do we see the output for columns like `host_is_superhost` 'twice' even though we don't expect it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in df.columns[56:62]:\n",
    "    series = df[c]\n",
    "    try:              # Try to do something\n",
    "        print('Summarising ' + series.name)\n",
    "        print(\"\\tMean:    {0:> 9.2f}\".format(series.mean()))\n",
    "        print(\"\\tMedian:  {0:> 9.2f}\".format(series.median()))\n",
    "    except TypeError: # If you see this problem don't blow up please!\n",
    "        print(\"Series \" + series.name + \" cannot be summarised numerically.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what the `except` does is allow us to intercept the error _before_ Python simply gives up and throws an error at you. For automation this is a really useful feature since it allows us to figure out if there are problems and do something about them before the user is left trying to figure out what went wrong! You should read up on these as they are very useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Graphs\n",
    "\n",
    "OK, so now we've got the `for` loop working and can handle issues relating to whether or not the column is actually numeric. So we've solved _one_ part of the problem. We can now move on to the _next_ part of the problem: creating a chart from each of the numeric columns.\n",
    "\n",
    "To help us make sense of the data it will be useful to add some additional information to our distribution plots: lines to show the location of the mean, median, and outlier thresholds.\n",
    "\n",
    "To do this, we need to get at the library that Seaborn itself uses: `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup work -- enables parameterisation\n",
    "series = df.price[df.score.abs() <= 6]\n",
    "fig = plt.figure(series.name)\n",
    "\n",
    "# Create the plot\n",
    "d    = sns.distplot(series)\n",
    "# Find the limits\n",
    "ymin = d.get_ylim()[0]\n",
    "ymax = d.get_ylim()[1]\n",
    "\n",
    "# Now add mean and median\n",
    "plt.vlines(series.mean(), ymin, ymax, colors='red', linestyles='solid', label='Mean')\n",
    "plt.vlines(series.median(), ymin, ymax, colors='green', linestyles='dashed', label='Median')\n",
    "\n",
    "# Add outlier marks (more than 1.5 times the IQR above or below the 1st and 3rd quartiles)\n",
    "iqr = series.quantile(0.75)-series.quantile(0.25)\n",
    "if series.quantile(0.25)-1.5*iqr > 0:\n",
    "    plt.vlines(series.quantile(0.25)-1.5*iqr, ymin, ymax, colors='blue', linestyles='dotted', label='Lower Outlier')\n",
    "if series.quantile(0.75)+1.5*iqr > 0:\n",
    "    plt.vlines(series.quantile(0.75)+1.5*iqr, ymin, ymax, colors='blue', linestyles='dotted', label='Upper Outlier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What just happened???\n",
    "?plt.vlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that you can also type `help(plt.vlines)` to discover what parameters a function takes. \n",
    "\n",
    "**Q7.** Why do you think I put an `if` condition on the outlier lines? Would this always be appropriate? Why? Why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Function\n",
    "\n",
    "Now that we've got the figure looking right for _one_ column, why don't we try to create a useful _function_ -- we _can_ always do this directly within the `for` loop, but a function is more elegant since it makes it simpler to see what is going on. I've created the basics of the function for you to illustrate this, but you'll need to do some extra legwork to figure out how to print out all of your graphs and summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.bed_type.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_plot(s):\n",
    "\n",
    "    fig = plt.figure(s.name)\n",
    "\n",
    "    # Create the plot\n",
    "    d    = sns.distplot(s.dropna())\n",
    "    # Find the limits\n",
    "    ymin = d.get_ylim()[0]\n",
    "    ymax = d.get_ylim()[1]\n",
    "\n",
    "    # Now add mean and median\n",
    "    plt.vlines(s.mean(), ymin, ymax, colors='red', linestyles='solid', label='Mean')\n",
    "    plt.vlines(s.median(), ymin, ymax, colors='green', linestyles='dashed', label='Median')\n",
    "\n",
    "    # Add outlier marks (more than 1.5 times the IQR above or below the 1st and 3rd quartiles)\n",
    "    iqr = s.quantile(0.75)-series.quantile(0.25)\n",
    "    if s.quantile(0.25)-1.5*iqr > 0:\n",
    "        plt.vlines(s.quantile(0.25)-1.5*iqr, ymin, ymax, colors='blue', linestyles='dotted', label='Lower Outlier')\n",
    "    if s.quantile(0.75)+1.5*iqr > 0:\n",
    "        plt.vlines(s.quantile(0.75)+1.5*iqr, ymin, ymax, colors='blue', linestyles='dotted', label='Upper Outlier')\n",
    "\n",
    "    fig = plt.gcf() # *G*et the *C*urrent *F*igure environment so that the next command works\n",
    "    plt.savefig(\"{0}-Automated.pdf\".format(s.name), bbox_inches=\"tight\")\n",
    "    plt.close() \n",
    "\n",
    "for c in df.columns[56:62]:\n",
    "    series = df[c]\n",
    "    print('Summarising ' + series.name)\n",
    "    try:              # Try to do something\n",
    "        \n",
    "        # Print numerical summaries\n",
    "        print(\"\\tMin:     {0:> 9.2f}\".format(series.min()))\n",
    "        print(\"\\tMax:     {0:> 9.2f}\".format(series.max()))\n",
    "        print(\"\\tMean:    {0:> 9.2f}\".format(series.mean()))\n",
    "        print(\"\\tMedian:  {0:> 9.2f}\".format(series.median()))\n",
    "        print(\"\\tIQR:     {0:> 9.2f}\".format(series.quantile(0.75)-series.quantile(0.25)))\n",
    "        \n",
    "        # Create graphical summary\n",
    "        print(\"\\tCreating graph...\")\n",
    "        create_plot(series)\n",
    "        \n",
    "    except TypeError: # If you see this problem don't blow up please!\n",
    "        print(\"\\tData cannot be summarised numerically.\")\n",
    "    ???: # Fix the error from bed_type, amenities, etc.\n",
    "        print(\"\\tProblem formatting string.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Types of Plots\n",
    "\n",
    "Using our data frame, let’s have a look at some other types of plots... We're also going to be playing with [aesthetics](https://seaborn.pydata.org/tutorial/aesthetics.html) that change how your plot looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "fig, ax = pyplot.subplots(figsize=(10,10))\n",
    "b = sns.boxplot(ax=ax, \n",
    "        x='neighbourhood_cleansed', \n",
    "        y='price', \n",
    "        data=df.sort_values(by='price'), \n",
    "        palette='PRGn', \n",
    "        fliersize=4, \n",
    "        linewidth=1)\n",
    "plt.ylim(0, 800)\n",
    "sns.despine(offset=10, trim=True)\n",
    "for item in b.get_xticklabels():\n",
    "    item.set_rotation('vertical')\n",
    "plt.title(\"Price Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "fig, ax = pyplot.subplots(figsize=(10,10))\n",
    "b = sns.violinplot(ax=ax, \n",
    "        x='neighbourhood_cleansed', \n",
    "        y='price', \n",
    "        data=df.sort_values(by='price'), \n",
    "        palette='PRGn', \n",
    "        fliersize=4, \n",
    "        linewidth=1)\n",
    "plt.ylim(0, 800)\n",
    "sns.despine(offset=10, trim=True)\n",
    "for item in b.get_xticklabels():\n",
    "    item.set_rotation('vertical')\n",
    "plt.title(\"Price Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.regplot(x='price', y='square_feet', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='price', y='bedrooms', col='neighbourhood_cleansed', data=df,\n",
    "          col_wrap=3, ci=None, palette='muted', size=4, \n",
    "          scatter_kws={'s':50, 'alpha': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot(df.bedrooms, df.bathrooms, color='#4CB391')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot(df.longitude, df.latitude, color='#4CB391')\n",
    "# Why might this 'map' not look right? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Plots\n",
    "Finally, I wanted to show you how to create a 3D scatter plot – in this case the plot doesn’t add a lot to our understanding of the data, but there are cases where it might and it does illustrate how pandas, seaborn, and matplotlib work together to produce some pretty incredible outputs.\n",
    "  \n",
    "I would encourage you to look into the options in more detail:\n",
    "* Can you change the colour map used to indicate which neighbourhood each listing is drawn from?\n",
    "* Can you change the icons used to mark each neighbourhood so that they are different?\n",
    "* Can you add a legend to indicate which marker is for which area?\n",
    "\n",
    "On with the show!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.colors as colours \n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "# Set up the figure\n",
    "w, h = 12, 8\n",
    "fig = plt.figure(figsize=(w, h))\n",
    "ax  = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Set up the 3D axes\n",
    "x = df.latitude\n",
    "y = df.longitude\n",
    "z = df.price\n",
    "\n",
    "# Set up the colourmap so that we see\n",
    "# different colours for each borough's\n",
    "# data.\n",
    "# From: http://stackoverflow.com/questions/28033046/matplotlib-scatter-color-by-categorical-factors\n",
    "boroughs  = list(set(df.neighbourhood_cleansed)) \n",
    "hot       = plt.get_cmap('hot')\n",
    "cNorm     = colours.Normalize(vmin=0, vmax=len(boroughs))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=hot)\n",
    "\n",
    "for i in xrange(len(boroughs)):\n",
    "    indx = df.neighbourhood_cleansed==boroughs[i]\n",
    "    ax.scatter(x[indx], y[indx], z[indx], c=scalarMap.to_rgba(i), marker='.')\n",
    "\n",
    "ax.set_xlabel(x.name)\n",
    "ax.set_ylabel(y.name)\n",
    "ax.set_zlabel(z.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally!\n",
    "\n",
    "Now redo all of this with the _full_ data set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy+paste code to here that you need to run the analysis\n",
    "# using the full data set (including outputing of charts and\n",
    "# summary stats) in one go. This will test if you reall 'got'\n",
    "# the hang of what we've done. You should also restart the \n",
    "# kernel to clear the existing variables from memory:\n",
    "#    Kernel > Restart [Note: not Restart & Clear Output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the display format of numbers from scientific\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [gsa2017]",
   "language": "python",
   "name": "Python [gsa2017]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
